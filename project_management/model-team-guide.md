# æ¨¡å‹åº”ç”¨ä¸è°ƒä¼˜å›¢é˜Ÿä»»åŠ¡æŒ‡å—

> **å›¢é˜Ÿè§„æ¨¡**: 2äºº
> **æ ¸å¿ƒèŒè´£**: æ„å»ºå¹¶ä¼˜åŒ–RAGæµç¨‹ã€è®¾è®¡æç¤ºè¯å·¥ç¨‹ã€æ„å»ºå‘é‡æ•°æ®åº“ã€ç®¡ç†æ¨¡å‹æ¥å£
> **æŠ€æœ¯æ ˆ**: é˜¿é‡Œäº‘æ–‡æ¡£æ™ºèƒ½ã€langgraphã€Weaviateã€Qwen3ç³»åˆ—æ¨¡å‹ã€OLLAMA

## ğŸ“‹ ä»»åŠ¡æ¦‚è§ˆ

### ä¸»è¦ä»»åŠ¡æ¸…å•
- [ ] **ä»»åŠ¡1**: æ•°æ®æ”¶é›†ä¸IDPé›†æˆ (é¢„è®¡3-4å¤©)
- [ ] **ä»»åŠ¡2**: å‘é‡æ•°æ®åº“æ„å»ºä¸é…ç½® (é¢„è®¡2-3å¤©)
- [ ] **ä»»åŠ¡3**: æ··åˆæ£€ç´¢ç®—æ³•å®ç° (é¢„è®¡4-5å¤©)
- [ ] **ä»»åŠ¡4**: æç¤ºè¯å·¥ç¨‹ä¸ä¼˜åŒ– (é¢„è®¡3-4å¤©)
- [ ] **ä»»åŠ¡5**: langgraph Agentæµç¨‹æ„å»º (é¢„è®¡5-6å¤©)
- [ ] **ä»»åŠ¡6**: æ¨¡å‹æ¥å£é›†æˆä¸æµ‹è¯• (é¢„è®¡2-3å¤©)
- [ ] **ä»»åŠ¡7**: (è¿›é˜¶)å°æ¨¡å‹å¾®è°ƒ (é¢„è®¡5-7å¤©ï¼Œå¯é€‰)

---

## ğŸ¯ ä»»åŠ¡1: æ•°æ®æ”¶é›†ä¸IDPé›†æˆ

### 1.1 æ•°æ®æ”¶é›†å‡†å¤‡ (ç¬¬1å¤©)

**ç›®æ ‡**: æ”¶é›†ç½‘ç»œè¿ç»´ç›¸å…³çš„çŸ¥è¯†æ–‡æ¡£ï¼Œä¸ºçŸ¥è¯†åº“æ„å»ºåšå‡†å¤‡ã€‚

**å…·ä½“æ­¥éª¤**:

1. **åˆ›å»ºæ•°æ®ç›®å½•ç»“æ„**
   ```bash
   mkdir -p assets/datasets/raw/{rfc,manuals,cases,others}
   mkdir -p assets/datasets/processed
   mkdir -p assets/datasets/embeddings
   ```

2. **æ”¶é›†RFCæ–‡æ¡£** (é‡ç‚¹æ”¶é›†ä»¥ä¸‹RFC)
   - RFC 2328 (OSPFv2)
   - RFC 4271 (BGP-4)
   - RFC 3031 (MPLSæ¶æ„)
   - RFC 4364 (BGP/MPLS IP VPN)
   - RFC 2547 (BGP/MPLS VPN)

   **ä¸‹è½½æ–¹å¼**: è®¿é—® https://tools.ietf.org/rfc/ ä¸‹è½½PDFç‰ˆæœ¬

3. **æ”¶é›†è®¾å¤‡æ‰‹å†Œ**
   - åä¸º: VRPç³»ç»Ÿé…ç½®æŒ‡å—ã€æ•…éšœå¤„ç†æ‰‹å†Œ
   - æ€ç§‘: IOSé…ç½®æŒ‡å—ã€æ•…éšœæ’é™¤æ‰‹å†Œ
   - åä¸‰: Comwareç³»ç»Ÿæ‰‹å†Œ

   **è·å–æ–¹å¼**: ä»å„å‚å•†å®˜ç½‘æŠ€æœ¯æ–‡æ¡£åŒºä¸‹è½½

4. **æ”¶é›†æ¡ˆä¾‹æ–‡æ¡£**
   - ç½‘ç»œæ•…éšœæ¡ˆä¾‹åˆ†æ
   - è¿ç»´æœ€ä½³å®è·µæ–‡æ¡£
   - æŠ€æœ¯åšå®¢å’Œè®ºå›ç²¾åå¸–

**éªŒæ”¶æ ‡å‡†**:
- æ”¶é›†åˆ°è‡³å°‘50ä¸ªé«˜è´¨é‡æ–‡æ¡£
- æ–‡æ¡£æŒ‰å‚å•†å’ŒæŠ€æœ¯åˆ†ç±»å­˜æ”¾
- å»ºç«‹æ–‡æ¡£æ¸…å•Excelè¡¨æ ¼ï¼Œè®°å½•æ–‡ä»¶åã€æ¥æºã€åˆ†ç±»ã€å‚å•†æ ‡ç­¾

### 1.2 é˜¿é‡Œäº‘æ–‡æ¡£æ™ºèƒ½æœåŠ¡é…ç½® (ç¬¬2å¤©)

**ç›®æ ‡**: é…ç½®å¹¶æµ‹è¯•é˜¿é‡Œäº‘æ–‡æ¡£æ™ºèƒ½æœåŠ¡ï¼Œç¡®ä¿èƒ½å¤Ÿé«˜è´¨é‡è§£æå„ç±»æ–‡æ¡£ã€‚

**å…·ä½“æ­¥éª¤**:

1. **å¼€é€šæœåŠ¡**
   - ç™»å½•é˜¿é‡Œäº‘æ§åˆ¶å°
   - æœç´¢"æ–‡æ¡£æ™ºèƒ½"æœåŠ¡å¹¶å¼€é€š
   - è·å–AccessKey IDå’ŒAccessKey Secret
   - è®°å½•æœåŠ¡endpointåœ°å€

2. **å®‰è£…SDK**
   ```bash
   pip install alibabacloud_tea_openapi alibabacloud_docmind_api20220711
   ```

3. **ç¼–å†™æµ‹è¯•è„šæœ¬** (`test_idp.py`)
   ```python
   from alibabacloud_docmind_api20220711.client import Client
   from alibabacloud_tea_openapi import models as open_api_models
   import base64
   import os

   def test_document_parsing():
       # é…ç½®å®¢æˆ·ç«¯
       config = open_api_models.Config(
           access_key_id='your_access_key_id',
           access_key_secret='your_access_key_secret',
           endpoint='docmind-api.cn-hangzhou.aliyuncs.com'
       )
       client = Client(config)

       # æµ‹è¯•æ–‡æ¡£è§£æ
       try:
           from alibabacloud_docmind_api20220711 import models as docmind_models

           # è¯»å–æµ‹è¯•æ–‡ä»¶
           test_file = "test_document.pdf"
           with open(test_file, 'rb') as f:
               file_content = base64.b64encode(f.read()).decode('utf-8')

           # æäº¤è§£æä»»åŠ¡
           request = docmind_models.SubmitDocumentExtractJobRequest(
               file_name=test_file,
               file_content=file_content
           )

           response = client.submit_document_extract_job(request)
           print(f"ä»»åŠ¡æäº¤æˆåŠŸï¼ŒJob ID: {response.body.data.id}")

       except Exception as e:
           print(f"æµ‹è¯•å¤±è´¥: {e}")
   ```

4. **æµ‹è¯•ä¸åŒæ–‡æ¡£ç±»å‹**
   - æµ‹è¯•PDFæ–‡æ¡£è§£æ
   - æµ‹è¯•æ‰«æä»¶OCR
   - æµ‹è¯•è¡¨æ ¼æå–
   - æµ‹è¯•å›¾æ–‡æ··æ’æ–‡æ¡£

**éªŒæ”¶æ ‡å‡†**:
- IDPæœåŠ¡é…ç½®æˆåŠŸï¼Œèƒ½æ­£å¸¸è°ƒç”¨API
- æµ‹è¯•è„šæœ¬èƒ½æˆåŠŸè§£æè‡³å°‘3ç§ä¸åŒç±»å‹çš„æ–‡æ¡£
- è§£æç»“æœåŒ…å«æ–‡æœ¬å†…å®¹ã€è¡¨æ ¼æ•°æ®ã€ç‰ˆé¢ä¿¡æ¯

### 1.3 è¯­ä¹‰åˆ‡åˆ†ç®—æ³•å®ç° (ç¬¬3-4å¤©)

**ç›®æ ‡**: åŸºäºIDPè¿”å›çš„ç»“æ„åŒ–æ•°æ®ï¼Œå®ç°è¯­ä¹‰æ„ŸçŸ¥çš„æ–‡æœ¬åˆ‡åˆ†ã€‚

**å…·ä½“æ­¥éª¤**:

1. **åˆ†æIDPè¿”å›æ•°æ®ç»“æ„**
   - ç ”ç©¶æ–‡æ¡£å±‚çº§æ ‘ç»“æ„
   - ç†è§£ç‰ˆé¢åˆ†æç»“æœ
   - è¯†åˆ«ä¸åŒå…ƒç´ ç±»å‹(æ ‡é¢˜ã€æ®µè½ã€è¡¨æ ¼ã€åˆ—è¡¨ç­‰)

2. **å®ç°è¯­ä¹‰åˆ‡åˆ†å™¨** (`semantic_splitter.py`)
   ```python
   class SemanticSplitter:
       def __init__(self, max_chunk_size=1000, overlap=100):
           self.max_chunk_size = max_chunk_size
           self.overlap = overlap

       def split_by_structure(self, idp_result):
           """åŸºäºæ–‡æ¡£ç»“æ„è¿›è¡Œè¯­ä¹‰åˆ‡åˆ†"""
           chunks = []
           # å®ç°åŸºäºå±‚çº§æ ‘çš„åˆ‡åˆ†é€»è¾‘
           return chunks
   ```

3. **å®ç°å…ƒæ•°æ®æå–**
   - æå–ç« èŠ‚æ ‡é¢˜ä½œä¸ºä¸Šä¸‹æ–‡
   - æ ‡è®°å…ƒç´ ç±»å‹(æ­£æ–‡/è¡¨æ ¼/ä»£ç )
   - è®°å½•é¡µç å’Œä½ç½®ä¿¡æ¯
   - è‡ªåŠ¨è¯†åˆ«å‚å•†æ ‡ç­¾

**éªŒæ”¶æ ‡å‡†**:
- åˆ‡åˆ†åçš„æ–‡æœ¬å—è¯­ä¹‰å®Œæ•´
- æ¯ä¸ªæ–‡æœ¬å—åŒ…å«ä¸°å¯Œçš„å…ƒæ•°æ®
- è¡¨æ ¼å’Œä»£ç å—ä¸è¢«åˆ‡æ–­
- ç”Ÿæˆçš„Markdownæ ¼å¼è§„èŒƒ

---

## ğŸ¯ ä»»åŠ¡2: å‘é‡æ•°æ®åº“æ„å»ºä¸é…ç½®

### 2.1 Weaviateæœ¬åœ°éƒ¨ç½² (ç¬¬1å¤©)

**ç›®æ ‡**: ä½¿ç”¨Dockeråœ¨æœ¬åœ°éƒ¨ç½²Weaviateå‘é‡æ•°æ®åº“ã€‚

**å…·ä½“æ­¥éª¤**:

1. **åˆ›å»ºDocker Composeé…ç½®** (`docker-compose.local.yml`)
   ```yaml
   version: '3.8'
   services:
     weaviate:
       image: semitechnologies/weaviate:1.21.2
       ports:
         - "8080:8080"
         - "50051:50051"
       environment:
         QUERY_DEFAULTS_LIMIT: 25
         AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
         PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
         DEFAULT_VECTORIZER_MODULE: 'none'
         ENABLE_MODULES: 'text2vec-openai,generative-openai'
         CLUSTER_HOSTNAME: 'node1'
       volumes:
         - weaviate_data:/var/lib/weaviate

   volumes:
     weaviate_data:
   ```

2. **å¯åŠ¨æœåŠ¡**
   ```bash
   docker-compose -f docker-compose.local.yml up -d
   ```

3. **éªŒè¯éƒ¨ç½²**
   ```bash
   curl http://localhost:8080/v1/meta
   ```

**éªŒæ”¶æ ‡å‡†**:
- WeaviateæœåŠ¡æ­£å¸¸å¯åŠ¨
- èƒ½é€šè¿‡REST APIè®¿é—®
- æ•°æ®æŒä¹…åŒ–é…ç½®æ­£ç¡®

### 2.2 Schemaè®¾è®¡ä¸åˆ›å»º (ç¬¬1å¤©)

**ç›®æ ‡**: è®¾è®¡é€‚åˆç½‘ç»œè¿ç»´çŸ¥è¯†çš„æ•°æ®Schemaã€‚

**å…·ä½“æ­¥éª¤**:

1. **è®¾è®¡Schemaç»“æ„** (`schema_design.py`)
   ```python
   KNOWLEDGE_SCHEMA = {
       "class": "KnowledgeChunk",
       "description": "ç½‘ç»œè¿ç»´çŸ¥è¯†ç‰‡æ®µ",
       "properties": [
           {
               "name": "content",
               "dataType": ["text"],
               "description": "æ–‡æœ¬å†…å®¹"
           },
           {
               "name": "title",
               "dataType": ["string"],
               "description": "æ ‡é¢˜æˆ–æ‘˜è¦"
           },
           {
               "name": "vendor",
               "dataType": ["string"],
               "description": "è®¾å¤‡å‚å•†"
           },
           {
               "name": "category",
               "dataType": ["string"],
               "description": "æŠ€æœ¯åˆ†ç±»"
           },
           {
               "name": "source_document",
               "dataType": ["string"],
               "description": "æºæ–‡æ¡£åç§°"
           },
           {
               "name": "page_number",
               "dataType": ["int"],
               "description": "é¡µç "
           }
       ],
       "vectorizer": "none"
   }
   ```

2. **åˆ›å»ºSchema**
   ```python
   import weaviate

   client = weaviate.Client("http://localhost:8080")
   client.schema.create_class(KNOWLEDGE_SCHEMA)
   ```

**éªŒæ”¶æ ‡å‡†**:
- Schemaåˆ›å»ºæˆåŠŸ
- å±æ€§å®šä¹‰å®Œæ•´åˆç†
- æ”¯æŒå…ƒæ•°æ®è¿‡æ»¤æŸ¥è¯¢

### 2.3 å‘é‡åŒ–æ¨¡å‹é›†æˆ (ç¬¬2å¤©)

**ç›®æ ‡**: é›†æˆé˜¿é‡Œäº‘ç™¾ç‚¼å¹³å°çš„text-embedding-v4æ¨¡å‹ã€‚

**å…·ä½“æ­¥éª¤**:

1. **é…ç½®ç™¾ç‚¼API**
   ```python
   from dashscope import TextEmbedding
   import os

   class QwenEmbedding:
       def __init__(self, api_key=None):
           self.api_key = api_key or os.environ.get('DASHSCOPE_API_KEY')

       def embed_text(self, text):
           response = TextEmbedding.call(
               model='text-embedding-v4',
               input=text,
               api_key=self.api_key
           )
           return response.output['embeddings'][0]['embedding']
   ```

2. **æ‰¹é‡å‘é‡åŒ–å·¥å…·**
   ```python
   def batch_embed_documents(documents, batch_size=10):
       embeddings = []
       for i in range(0, len(documents), batch_size):
           batch = documents[i:i+batch_size]
           # æ‰¹é‡è°ƒç”¨embedding API
           batch_embeddings = embed_batch(batch)
           embeddings.extend(batch_embeddings)
       return embeddings
   ```

**éªŒæ”¶æ ‡å‡†**:
- èƒ½æˆåŠŸè°ƒç”¨text-embedding-v4 API
- æ”¯æŒæ‰¹é‡å‘é‡åŒ–å¤„ç†
- å‘é‡ç»´åº¦æ­£ç¡®(é€šå¸¸1536ç»´)

---

## ğŸ¯ ä»»åŠ¡3: æ··åˆæ£€ç´¢ç®—æ³•å®ç°

### 3.1 BM25å…³é”®è¯æ£€ç´¢ (ç¬¬1å¤©)

**ç›®æ ‡**: å®ç°åŸºäºBM25ç®—æ³•çš„å…³é”®è¯æ£€ç´¢ã€‚

**å…·ä½“æ­¥éª¤**:

1. **é…ç½®Weaviate BM25**
   ```python
   def bm25_search(client, query, limit=50):
       result = client.query.get("KnowledgeChunk", [
           "content", "title", "vendor", "category"
       ]).with_bm25(
           query=query
       ).with_limit(limit).do()

       return result
   ```

2. **å…³é”®è¯é¢„å¤„ç†**
   ```python
   def preprocess_query(query):
       # ç½‘ç»œæœ¯è¯­æ ‡å‡†åŒ–
       # åŒä¹‰è¯æ‰©å±•
       # åœç”¨è¯è¿‡æ»¤
       return processed_query
   ```

**éªŒæ”¶æ ‡å‡†**:
- BM25æ£€ç´¢åŠŸèƒ½æ­£å¸¸
- èƒ½æ£€ç´¢åˆ°ç›¸å…³æ–‡æ¡£
- æ”¯æŒä¸­è‹±æ–‡æ··åˆæŸ¥è¯¢

### 3.2 å‘é‡è¯­ä¹‰æ£€ç´¢ (ç¬¬2å¤©)

**ç›®æ ‡**: å®ç°åŸºäºå‘é‡ç›¸ä¼¼åº¦çš„è¯­ä¹‰æ£€ç´¢ã€‚

**å…·ä½“æ­¥éª¤**:

1. **å‘é‡æ£€ç´¢å®ç°**
   ```python
   def vector_search(client, query_vector, limit=50):
       result = client.query.get("KnowledgeChunk", [
           "content", "title", "vendor", "category"
       ]).with_near_vector({
           "vector": query_vector
       }).with_limit(limit).do()

       return result
   ```

2. **ç›¸ä¼¼åº¦è®¡ç®—ä¼˜åŒ–**
   - å®ç°ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—
   - è®¾ç½®ç›¸ä¼¼åº¦é˜ˆå€¼
   - å¤„ç†å‘é‡å½’ä¸€åŒ–

**éªŒæ”¶æ ‡å‡†**:
- å‘é‡æ£€ç´¢åŠŸèƒ½æ­£å¸¸
- ç›¸ä¼¼åº¦è®¡ç®—å‡†ç¡®
- æ£€ç´¢é€Ÿåº¦æ»¡è¶³è¦æ±‚(< 500ms)

### 3.3 æ··åˆæ£€ç´¢ä¸é‡æ’åº (ç¬¬3-4å¤©)

**ç›®æ ‡**: å®ç°ä¸¤é˜¶æ®µæ£€ç´¢ï¼šå¬å›+ç²¾æ’ã€‚

**å…·ä½“æ­¥éª¤**:

1. **æ··åˆå¬å›ç­–ç•¥**
   ```python
   def hybrid_recall(query, bm25_weight=0.3, vector_weight=0.7):
       # å…³é”®è¯å¬å›
       bm25_results = bm25_search(query, limit=50)

       # å‘é‡å¬å›
       query_vector = embed_text(query)
       vector_results = vector_search(query_vector, limit=50)

       # ç»“æœåˆå¹¶å»é‡
       combined_results = merge_and_deduplicate(
           bm25_results, vector_results,
           bm25_weight, vector_weight
       )

       return combined_results
   ```

2. **é‡æ’åºæ¨¡å‹é›†æˆ**
   ```python
   # ä½¿ç”¨OLLAMAéƒ¨ç½²Qwen3-Reranker
   def setup_reranker():
       # ä¸‹è½½å¹¶å¯åŠ¨OLLAMA
       # æ‹‰å–Qwen3-Rerankeræ¨¡å‹
       pass

   def rerank_documents(query, documents, top_k=5):
       # è°ƒç”¨é‡æ’åºæ¨¡å‹
       scores = []
       for doc in documents:
           score = call_reranker_api(query, doc['content'])
           scores.append(score)

       # æŒ‰åˆ†æ•°æ’åºå¹¶è¿”å›top_k
       ranked_docs = sort_by_score(documents, scores)[:top_k]
       return ranked_docs
   ```

**éªŒæ”¶æ ‡å‡†**:
- æ··åˆæ£€ç´¢å¬å›ç‡é«˜(>80%)
- é‡æ’åºæ¨¡å‹éƒ¨ç½²æˆåŠŸ
- æœ€ç»ˆæ£€ç´¢ç²¾åº¦æ˜æ˜¾æå‡

---

## ğŸ¯ ä»»åŠ¡4: æç¤ºè¯å·¥ç¨‹ä¸ä¼˜åŒ–

### 4.1 åŸºç¡€Promptè®¾è®¡ (ç¬¬1å¤©)

**ç›®æ ‡**: è®¾è®¡ç”¨äºä¸åŒåœºæ™¯çš„åŸºç¡€æç¤ºè¯æ¨¡æ¿ã€‚

**å…·ä½“æ­¥éª¤**:

1. **åˆ†æèŠ‚ç‚¹Prompt** (`prompts/analysis_prompt.py`)
   ```python
   ANALYSIS_PROMPT = """
   ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ç½‘ç»œè¿ç»´ä¸“å®¶ã€‚è¯·åˆ†æç”¨æˆ·æå‡ºçš„ç½‘ç»œé—®é¢˜ã€‚

   ç”¨æˆ·é—®é¢˜: {user_query}

   ä¸Šä¸‹æ–‡ä¿¡æ¯:
   {context}

   è¯·æŒ‰ä»¥ä¸‹æ ¼å¼åˆ†æ:
   1. é—®é¢˜åˆ†ç±»: [OSPF/BGP/MPLS/VPN/å…¶ä»–]
   2. å¯èƒ½åŸå› : åˆ—å‡º3-5ä¸ªå¯èƒ½çš„åŸå› 
   3. éœ€è¦è¡¥å……çš„ä¿¡æ¯: å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œåˆ—å‡ºéœ€è¦ç”¨æˆ·æä¾›çš„å…·ä½“ä¿¡æ¯
   4. åˆæ­¥å»ºè®®: ç»™å‡ºåˆæ­¥çš„æ’æŸ¥æ–¹å‘

   å¦‚æœä¿¡æ¯ä¸è¶³ä»¥ç»™å‡ºå®Œæ•´åˆ†æï¼Œè¯·åœ¨å›ç­”æœ«å°¾æ·»åŠ : [NEED_MORE_INFO]
   """
   ```

2. **è¿½é—®èŠ‚ç‚¹Prompt**
   ```python
   CLARIFICATION_PROMPT = """
   åŸºäºå½“å‰çš„åˆ†æï¼Œæˆ‘éœ€è¦æ›´å¤šä¿¡æ¯æ¥å¸®åŠ©æ‚¨è§£å†³é—®é¢˜ã€‚

   å½“å‰åˆ†æ: {current_analysis}

   è¯·å›ç­”ä»¥ä¸‹é—®é¢˜:
   {questions}

   æ‚¨ä¹Ÿå¯ä»¥ä¸Šä¼ ç›¸å…³çš„é…ç½®æ–‡ä»¶ã€æ—¥å¿—æ–‡ä»¶æˆ–ç½‘ç»œæ‹“æ‰‘å›¾ã€‚
   """
   ```

3. **è§£å†³æ–¹æ¡ˆç”ŸæˆPrompt**
   ```python
   SOLUTION_PROMPT = """
   ä½ æ˜¯ä¸€ä½{vendor}ç½‘ç»œè®¾å¤‡ä¸“å®¶ã€‚åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œæä¾›è¯¦ç»†çš„è§£å†³æ–¹æ¡ˆã€‚

   é—®é¢˜æè¿°: {problem}
   ç›¸å…³æ–‡æ¡£: {retrieved_docs}
   ç”¨æˆ·è¡¥å……ä¿¡æ¯: {user_context}

   è¯·æä¾›:
   1. é—®é¢˜æ ¹å› åˆ†æ
   2. è¯¦ç»†è§£å†³æ­¥éª¤ (æ¯æ­¥éƒ½è¦å…·ä½“å¯æ‰§è¡Œ)
   3. éªŒè¯æ–¹æ³•
   4. é¢„é˜²æªæ–½

   åœ¨å¼•ç”¨æ–‡æ¡£å†…å®¹æ—¶ï¼Œè¯·ä½¿ç”¨ [doc1], [doc2] ç­‰æ ‡è®°ã€‚
   æ‰€æœ‰å‘½ä»¤éƒ½è¦ä½¿ç”¨{vendor}çš„è¯­æ³•æ ¼å¼ã€‚
   """
   ```

**éªŒæ”¶æ ‡å‡†**:
- Promptæ¨¡æ¿è¦†ç›–æ‰€æœ‰èŠ‚ç‚¹ç±»å‹
- æ¨¡æ¿æ”¯æŒå˜é‡æ›¿æ¢
- è¾“å‡ºæ ¼å¼è§„èŒƒç»Ÿä¸€

### 4.2 å‚å•†é€‚é…Prompt (ç¬¬2å¤©)

**ç›®æ ‡**: ä¸ºä¸åŒå‚å•†è®¾å¤‡å®šåˆ¶ä¸“é—¨çš„æç¤ºè¯ã€‚

**å…·ä½“æ­¥éª¤**:

1. **åä¸ºVRPç³»ç»ŸPrompt**
   ```python
   HUAWEI_PROMPT = """
   ä½ æ˜¯åä¸ºVRPç³»ç»Ÿä¸“å®¶ã€‚è¯·ä½¿ç”¨åä¸ºè®¾å¤‡çš„å‘½ä»¤è¯­æ³•å›ç­”é—®é¢˜ã€‚

   å¸¸ç”¨å‘½ä»¤æ ¼å¼:
   - æŸ¥çœ‹æ¥å£: display interface
   - æŸ¥çœ‹è·¯ç”±: display ip routing-table
   - æŸ¥çœ‹OSPF: display ospf peer
   - é…ç½®æ¥å£: interface GigabitEthernet0/0/1

   {base_prompt}

   æ³¨æ„: æ‰€æœ‰å‘½ä»¤å¿…é¡»ç¬¦åˆVRPè¯­æ³•è§„èŒƒã€‚
   """
   ```

2. **æ€ç§‘IOSç³»ç»ŸPrompt**
   ```python
   CISCO_PROMPT = """
   ä½ æ˜¯æ€ç§‘IOSç³»ç»Ÿä¸“å®¶ã€‚è¯·ä½¿ç”¨æ€ç§‘è®¾å¤‡çš„å‘½ä»¤è¯­æ³•å›ç­”é—®é¢˜ã€‚

   å¸¸ç”¨å‘½ä»¤æ ¼å¼:
   - æŸ¥çœ‹æ¥å£: show interfaces
   - æŸ¥çœ‹è·¯ç”±: show ip route
   - æŸ¥çœ‹OSPF: show ip ospf neighbor
   - é…ç½®æ¥å£: interface GigabitEthernet0/0

   {base_prompt}

   æ³¨æ„: æ‰€æœ‰å‘½ä»¤å¿…é¡»ç¬¦åˆIOSè¯­æ³•è§„èŒƒã€‚
   """
   ```

**éªŒæ”¶æ ‡å‡†**:
- æ”¯æŒä¸»æµå‚å•†(åä¸ºã€æ€ç§‘ã€åä¸‰)
- å‘½ä»¤è¯­æ³•å‡†ç¡®æ— è¯¯
- èƒ½æ ¹æ®ä¸Šä¸‹æ–‡è‡ªåŠ¨é€‰æ‹©å‚å•†

### 4.3 å¼•ç”¨æ ‡è®°ä¸æº¯æº (ç¬¬3å¤©)

**ç›®æ ‡**: å®ç°ç­”æ¡ˆçš„å¼•ç”¨æ ‡è®°å’ŒçŸ¥è¯†æº¯æºåŠŸèƒ½ã€‚

**å…·ä½“æ­¥éª¤**:

1. **å¼•ç”¨æ ‡è®°Prompt**
   ```python
   CITATION_PROMPT = """
   åœ¨ç”Ÿæˆç­”æ¡ˆæ—¶ï¼Œå¿…é¡»ä¸ºæ¯ä¸ªå¼•ç”¨çš„ä¿¡æ¯æ·»åŠ æ ‡è®°ã€‚

   å¼•ç”¨æ ¼å¼: [doc{åºå·}]

   ç¤ºä¾‹:
   "æ ¹æ®RFC 2328è§„å®šï¼ŒOSPFé‚»å±…å…³ç³»å»ºç«‹éœ€è¦ç»è¿‡Downã€Initã€2-Wayã€ExStartã€Exchangeã€Loadingã€Fullä¸ƒä¸ªçŠ¶æ€ [doc1]ã€‚
   å¦‚æœå¡åœ¨ExStartçŠ¶æ€ï¼Œé€šå¸¸æ˜¯MTUä¸åŒ¹é…å¯¼è‡´çš„ [doc2]ã€‚"

   å¼•ç”¨çš„æ–‡æ¡£ä¿¡æ¯:
   {source_documents}

   è¯·ä¸¥æ ¼æŒ‰ç…§æ­¤æ ¼å¼æ·»åŠ å¼•ç”¨æ ‡è®°ã€‚
   """
   ```

2. **æº¯æºä¿¡æ¯æå–**
   ```python
   def extract_citations(answer_text, source_docs):
       citations = []
       # æå–[doc1], [doc2]ç­‰æ ‡è®°
       # åŒ¹é…å¯¹åº”çš„æºæ–‡æ¡£ä¿¡æ¯
       return citations
   ```

**éªŒæ”¶æ ‡å‡†**:
- ç­”æ¡ˆä¸­æ­£ç¡®æ·»åŠ å¼•ç”¨æ ‡è®°
- å¼•ç”¨ä¿¡æ¯å‡†ç¡®å¯¹åº”æºæ–‡æ¡£
- æ”¯æŒç‚¹å‡»æŸ¥çœ‹åŸæ–‡

### 4.4 Promptæ•ˆæœæµ‹è¯•ä¸ä¼˜åŒ– (ç¬¬4å¤©)

**ç›®æ ‡**: æµ‹è¯•å’Œä¼˜åŒ–æç¤ºè¯æ•ˆæœã€‚

**å…·ä½“æ­¥éª¤**:

1. **æ„å»ºæµ‹è¯•ç”¨ä¾‹**
   ```python
   TEST_CASES = [
       {
           "query": "OSPFé‚»å±…çŠ¶æ€å¡åœ¨ExStartæ€ä¹ˆåŠï¼Ÿ",
           "expected_keywords": ["MTU", "æ¥å£", "é…ç½®"],
           "expected_vendor": "é€šç”¨"
       },
       {
           "query": "åä¸ºè®¾å¤‡BGPé‚»å±…å»ºç«‹å¤±è´¥",
           "expected_keywords": ["peer", "ASå·", "è·¯ç”±å™¨ID"],
           "expected_vendor": "åä¸º"
       }
   ]
   ```

2. **è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬**
   ```python
   def test_prompt_quality(test_cases):
       results = []
       for case in test_cases:
           response = generate_answer(case['query'])
           score = evaluate_response(response, case)
           results.append(score)
       return results
   ```

**éªŒæ”¶æ ‡å‡†**:
- æµ‹è¯•ç”¨ä¾‹è¦†ç›–ä¸»è¦åœºæ™¯
- ç­”æ¡ˆè´¨é‡è¯„åˆ†>80%
- Promptè¿­ä»£ä¼˜åŒ–å®Œæˆ

---

## ğŸ¯ ä»»åŠ¡5: langgraph Agentæµç¨‹æ„å»º

### 5.1 çŠ¶æ€æœºè®¾è®¡ (ç¬¬1å¤©)

**ç›®æ ‡**: è®¾è®¡å¤šè½®å¯¹è¯çš„çŠ¶æ€æœºæ¶æ„ã€‚

**å…·ä½“æ­¥éª¤**:

1. **å®šä¹‰çŠ¶æ€ç»“æ„**
   ```python
   from typing import TypedDict, List

   class AgentState(TypedDict):
       messages: List[dict]  # å¯¹è¯å†å²
       context: List[dict]   # æ£€ç´¢åˆ°çš„çŸ¥è¯†
       user_query: str       # ç”¨æˆ·é—®é¢˜
       vendor: str          # è®¾å¤‡å‚å•†
       category: str        # é—®é¢˜åˆ†ç±»
       need_more_info: bool # æ˜¯å¦éœ€è¦æ›´å¤šä¿¡æ¯
       solution_ready: bool # æ˜¯å¦å¯ä»¥ç»™å‡ºè§£å†³æ–¹æ¡ˆ
   ```

2. **è®¾è®¡èŠ‚ç‚¹ç±»å‹**
   ```python
   # åˆ†æèŠ‚ç‚¹
   def analyze_query(state: AgentState) -> AgentState:
       # åˆ†æç”¨æˆ·é—®é¢˜
       # åˆ†ç±»é—®é¢˜ç±»å‹
       # è¯†åˆ«å‚å•†ä¿¡æ¯
       pass

   # æ£€ç´¢èŠ‚ç‚¹
   def retrieve_knowledge(state: AgentState) -> AgentState:
       # æ‰§è¡Œæ··åˆæ£€ç´¢
       # æ›´æ–°context
       pass

   # è¿½é—®èŠ‚ç‚¹
   def ask_clarification(state: AgentState) -> AgentState:
       # ç”Ÿæˆè¿½é—®é—®é¢˜
       # ç­‰å¾…ç”¨æˆ·å›ç­”
       pass

   # è§£å†³æ–¹æ¡ˆèŠ‚ç‚¹
   def generate_solution(state: AgentState) -> AgentState:
       # ç”Ÿæˆæœ€ç»ˆè§£å†³æ–¹æ¡ˆ
       # æ·»åŠ å¼•ç”¨æ ‡è®°
       pass
   ```

**éªŒæ”¶æ ‡å‡†**:
- çŠ¶æ€ç»“æ„è®¾è®¡åˆç†
- èŠ‚ç‚¹åŠŸèƒ½åˆ’åˆ†æ¸…æ™°
- æ”¯æŒçŠ¶æ€ä¼ é€’å’Œæ›´æ–°

### 5.2 å·¥ä½œæµç¼–æ’ (ç¬¬2-3å¤©)

**ç›®æ ‡**: ä½¿ç”¨langgraphæ„å»ºå®Œæ•´çš„å¯¹è¯æµç¨‹ã€‚

**å…·ä½“æ­¥éª¤**:

1. **åˆ›å»ºçŠ¶æ€å›¾**
   ```python
   from langgraph.graph import StateGraph, END

   def create_agent_graph():
       workflow = StateGraph(AgentState)

       # æ·»åŠ èŠ‚ç‚¹
       workflow.add_node("analyze", analyze_query)
       workflow.add_node("retrieve", retrieve_knowledge)
       workflow.add_node("clarify", ask_clarification)
       workflow.add_node("solve", generate_solution)

       # å®šä¹‰è¾¹å’Œæ¡ä»¶
       workflow.set_entry_point("analyze")

       workflow.add_conditional_edges(
           "analyze",
           should_retrieve,
           {
               "retrieve": "retrieve",
               "clarify": "clarify"
           }
       )

       workflow.add_conditional_edges(
           "retrieve",
           should_solve_or_clarify,
           {
               "solve": "solve",
               "clarify": "clarify"
           }
       )

       workflow.add_edge("clarify", "analyze")
       workflow.add_edge("solve", END)

       return workflow.compile()
   ```

2. **å®ç°æ¡ä»¶åˆ¤æ–­å‡½æ•°**
   ```python
   def should_retrieve(state: AgentState) -> str:
       if state.get("category") and not state.get("need_more_info"):
           return "retrieve"
       return "clarify"

   def should_solve_or_clarify(state: AgentState) -> str:
       if len(state["context"]) > 0 and not state.get("need_more_info"):
           return "solve"
       return "clarify"
   ```

**éªŒæ”¶æ ‡å‡†**:
- å·¥ä½œæµé€»è¾‘æ­£ç¡®
- æ¡ä»¶åˆ¤æ–­å‡†ç¡®
- æ”¯æŒå¤šè½®å¯¹è¯

### 5.3 Agentæµ‹è¯•ä¸è°ƒè¯• (ç¬¬4-5å¤©)

**ç›®æ ‡**: æµ‹è¯•Agentçš„å®Œæ•´å¯¹è¯æµç¨‹ã€‚

**å…·ä½“æ­¥éª¤**:

1. **å•å…ƒæµ‹è¯•**
   ```python
   def test_analyze_node():
       state = {"user_query": "OSPFé‚»å±…å»ºç«‹å¤±è´¥"}
       result = analyze_query(state)
       assert result["category"] == "OSPF"

   def test_retrieve_node():
       state = {"user_query": "BGPé…ç½®", "category": "BGP"}
       result = retrieve_knowledge(state)
       assert len(result["context"]) > 0
   ```

2. **é›†æˆæµ‹è¯•**
   ```python
   def test_full_conversation():
       agent = create_agent_graph()

       # æµ‹è¯•å®Œæ•´å¯¹è¯æµç¨‹
       initial_state = {
           "user_query": "åä¸ºè®¾å¤‡OSPFé‚»å±…çŠ¶æ€å¼‚å¸¸",
           "messages": []
       }

       final_state = agent.invoke(initial_state)
       assert final_state["solution_ready"] == True
   ```

**éªŒæ”¶æ ‡å‡†**:
- æ‰€æœ‰èŠ‚ç‚¹å•å…ƒæµ‹è¯•é€šè¿‡
- å®Œæ•´å¯¹è¯æµç¨‹æµ‹è¯•é€šè¿‡
- Agentèƒ½æ­£ç¡®å¤„ç†å„ç§åœºæ™¯

---

## ğŸ¯ ä»»åŠ¡6: æ¨¡å‹æ¥å£é›†æˆä¸æµ‹è¯•

### 6.1 ç™¾ç‚¼å¤§æ¨¡å‹APIé›†æˆ (ç¬¬1å¤©)

**ç›®æ ‡**: é›†æˆé˜¿é‡Œäº‘ç™¾ç‚¼å¹³å°çš„qwen-plusæ¨¡å‹ã€‚

**å…·ä½“æ­¥éª¤**:

1. **é…ç½®APIå®¢æˆ·ç«¯**
   ```python
   from dashscope import Generation
   from langchain_openai import ChatOpenAI
   import os

   class QwenLLM:
       def __init__(self, api_key=None, model="qwen-plus"):
           self.api_key = api_key or os.environ.get('DASHSCOPE_API_KEY')
           self.model = model

       def generate(self, prompt, max_tokens=2000):
           response = Generation.call(
               model=self.model,
               prompt=prompt,
               api_key=self.api_key,
               max_tokens=max_tokens,
               temperature=0.1
           )
           return response.output.text

   # ä½¿ç”¨langchain_openaiçš„æ–¹å¼ï¼ˆæ¨èï¼‰
   class QwenLangChain:
       def __init__(self, api_key=None, model="qwen-plus"):
           self.llm = ChatOpenAI(
               model=model,
               openai_api_key=api_key or os.environ.get('DASHSCOPE_API_KEY'),
               openai_api_base="https://dashscope.aliyuncs.com/compatible-mode/v1",
               temperature=0.1
           )

       def generate(self, messages):
           response = self.llm.invoke(messages)
           return response.content
   ```

2. **å®ç°æµå¼è¾“å‡º**
   ```python
   def stream_generate(self, prompt):
       responses = Generation.call(
           model=self.model,
           prompt=prompt,
           api_key=self.api_key,
           stream=True
       )

       for response in responses:
           yield response.output.text
   ```

**éªŒæ”¶æ ‡å‡†**:
- APIè°ƒç”¨æˆåŠŸ
- æ”¯æŒæµå¼å’Œéæµå¼è¾“å‡º
- é”™è¯¯å¤„ç†å®Œå–„

### 6.2 æ€§èƒ½ä¼˜åŒ–ä¸ç›‘æ§ (ç¬¬2å¤©)

**ç›®æ ‡**: ä¼˜åŒ–æ¨¡å‹è°ƒç”¨æ€§èƒ½ï¼Œæ·»åŠ ç›‘æ§ã€‚

**å…·ä½“æ­¥éª¤**:

1. **æ·»åŠ ç¼“å­˜æœºåˆ¶**
   ```python
   import redis
   import hashlib

   class CachedLLM:
       def __init__(self, llm, redis_client):
           self.llm = llm
           self.redis = redis_client

       def generate_with_cache(self, prompt):
           # è®¡ç®—prompt hash
           prompt_hash = hashlib.md5(prompt.encode()).hexdigest()

           # æ£€æŸ¥ç¼“å­˜
           cached = self.redis.get(prompt_hash)
           if cached:
               return cached.decode()

           # è°ƒç”¨æ¨¡å‹
           result = self.llm.generate(prompt)

           # å­˜å…¥ç¼“å­˜
           self.redis.setex(prompt_hash, 3600, result)
           return result
   ```

2. **æ·»åŠ æ€§èƒ½ç›‘æ§**
   ```python
   import time
   import logging

   def monitor_llm_call(func):
       def wrapper(*args, **kwargs):
           start_time = time.time()
           try:
               result = func(*args, **kwargs)
               duration = time.time() - start_time
               logging.info(f"LLM call success: {duration:.2f}s")
               return result
           except Exception as e:
               duration = time.time() - start_time
               logging.error(f"LLM call failed: {duration:.2f}s, {e}")
               raise
       return wrapper
   ```

**éªŒæ”¶æ ‡å‡†**:
- ç¼“å­˜æœºåˆ¶å·¥ä½œæ­£å¸¸
- æ€§èƒ½ç›‘æ§æ•°æ®å‡†ç¡®
- å¹³å‡å“åº”æ—¶é—´<3ç§’

---

## ğŸ¯ ä»»åŠ¡7: (è¿›é˜¶)å°æ¨¡å‹å¾®è°ƒ

### 7.1 æ•°æ®å‡†å¤‡ (ç¬¬1-2å¤©)

**ç›®æ ‡**: å‡†å¤‡ç”¨äºå¾®è°ƒçš„è®­ç»ƒæ•°æ®é›†ã€‚

**å…·ä½“æ­¥éª¤**:

1. **æ”¶é›†é—®é¢˜åˆ†ç±»æ•°æ®**
   ```python
   # æ„å»ºé—®é¢˜åˆ†ç±»æ•°æ®é›†
   classification_data = [
       {"text": "OSPFé‚»å±…å»ºç«‹å¤±è´¥", "label": "OSPF"},
       {"text": "BGPè·¯ç”±ä¸é€š", "label": "BGP"},
       {"text": "MPLS VPNé…ç½®é—®é¢˜", "label": "MPLS"},
       # ... æ›´å¤šæ•°æ®
   ]
   ```

2. **æ•°æ®æ¸…æ´—å’Œæ ‡æ³¨**
   - å»é‡å’Œæ ¼å¼ç»Ÿä¸€
   - äººå·¥æ ‡æ³¨å’Œæ ¡éªŒ
   - æ•°æ®é›†åˆ’åˆ†(è®­ç»ƒ/éªŒè¯/æµ‹è¯•)

**éªŒæ”¶æ ‡å‡†**:
- æ”¶é›†åˆ°1000+æ ‡æ³¨æ ·æœ¬
- æ•°æ®è´¨é‡é«˜ï¼Œæ ‡æ³¨å‡†ç¡®
- æ•°æ®é›†åˆ’åˆ†åˆç†

### 7.2 æ¨¡å‹å¾®è°ƒ (ç¬¬3-5å¤©)

**ç›®æ ‡**: å¾®è°ƒBERTæ¨¡å‹ç”¨äºé—®é¢˜æ„å›¾åˆ†ç±»ã€‚

**å…·ä½“æ­¥éª¤**:

1. **é€‰æ‹©åŸºç¡€æ¨¡å‹**
   ```python
   from transformers import AutoTokenizer, AutoModelForSequenceClassification

   model_name = "bert-base-chinese"
   tokenizer = AutoTokenizer.from_pretrained(model_name)
   model = AutoModelForSequenceClassification.from_pretrained(
       model_name,
       num_labels=len(categories)
   )
   ```

2. **è®­ç»ƒè„šæœ¬**
   ```python
   from transformers import Trainer, TrainingArguments

   training_args = TrainingArguments(
       output_dir="./results",
       num_train_epochs=3,
       per_device_train_batch_size=16,
       per_device_eval_batch_size=64,
       warmup_steps=500,
       weight_decay=0.01,
       logging_dir="./logs",
   )

   trainer = Trainer(
       model=model,
       args=training_args,
       train_dataset=train_dataset,
       eval_dataset=eval_dataset,
   )

   trainer.train()
   ```

**éªŒæ”¶æ ‡å‡†**:
- æ¨¡å‹è®­ç»ƒå®Œæˆ
- éªŒè¯é›†å‡†ç¡®ç‡>85%
- æ¨¡å‹å¯ä»¥æ­£å¸¸æ¨ç†

---

## ğŸ“Š è¿›åº¦è·Ÿè¸ªä¸è´¨é‡æ§åˆ¶

### æ¯æ—¥ç«™ä¼š
- **æ—¶é—´**: æ¯å¤©ä¸Šåˆ9:30
- **å†…å®¹**: æ±‡æŠ¥æ˜¨æ—¥å®Œæˆæƒ…å†µã€ä»Šæ—¥è®¡åˆ’ã€é‡åˆ°çš„é—®é¢˜
- **å‚ä¸äºº**: æ¨¡å‹å›¢é˜Ÿ2äºº + é¡¹ç›®è´Ÿè´£äºº

### è´¨é‡æ£€æŸ¥ç‚¹
1. **ç¬¬ä¸€å‘¨æœ«**: æ•°æ®æ”¶é›†å’ŒIDPé›†æˆå®Œæˆåº¦æ£€æŸ¥
2. **ç¬¬äºŒå‘¨æœ«**: å‘é‡æ•°æ®åº“å’Œæ£€ç´¢ç®—æ³•éªŒæ”¶
3. **ç¬¬ä¸‰å‘¨æœ«**: Agentæµç¨‹å’Œæ¨¡å‹é›†æˆæµ‹è¯•

### äº¤ä»˜ç‰©æ¸…å•
- [ ] å¤„ç†åçš„çŸ¥è¯†åº“æ•°æ®é›†
- [ ] Weaviateå‘é‡æ•°æ®åº“(åŒ…å«ç´¢å¼•æ•°æ®)
- [ ] æ··åˆæ£€ç´¢ç®—æ³•ä»£ç 
- [ ] langgraph Agentå·¥ä½œæµ
- [ ] æç¤ºè¯æ¨¡æ¿åº“
- [ ] æ¨¡å‹æ¥å£å°è£…ä»£ç 
- [ ] æŠ€æœ¯æ–‡æ¡£å’Œä½¿ç”¨è¯´æ˜

### é£é™©é¢„æ¡ˆ
1. **IDPæœåŠ¡è°ƒç”¨å¤±è´¥**: å‡†å¤‡æœ¬åœ°OCRå¤‡é€‰æ–¹æ¡ˆ
2. **å‘é‡åŒ–APIé™æµ**: å®ç°è¯·æ±‚é˜Ÿåˆ—å’Œé‡è¯•æœºåˆ¶
3. **æ¨¡å‹æ•ˆæœä¸ä½³**: å‡†å¤‡å¤šä¸ªPromptç‰ˆæœ¬è¿›è¡ŒA/Bæµ‹è¯•

---

## ğŸ”§ å¼€å‘ç¯å¢ƒé…ç½®

### å¿…éœ€è½¯ä»¶
- Python 3.9+
- Docker & Docker Compose
- Git
- OLLAMA (ç”¨äºæœ¬åœ°æ¨¡å‹éƒ¨ç½²)

### Pythonä¾èµ–
```bash
pip install dashscope weaviate-client langgraph langchain langchain_openai redis transformers torch alibabacloud_tea_openapi alibabacloud_docmind_api20220711
```

### ç¯å¢ƒå˜é‡é…ç½®
```bash
export DASHSCOPE_API_KEY="your_dashscope_api_key"
export WEAVIATE_URL="http://localhost:8080"
export REDIS_URL="redis://localhost:6379"

# ç”¨äºlangchain_openaiè®¿é—®Qwen-Plus
export OPENAI_API_KEY="your_dashscope_api_key"
export OPENAI_API_BASE="https://dashscope.aliyuncs.com/compatible-mode/v1"

# é˜¿é‡Œäº‘æ–‡æ¡£æ™ºèƒ½æœåŠ¡
export ALIBABA_ACCESS_KEY_ID="your_access_key_id"
export ALIBABA_ACCESS_KEY_SECRET="your_access_key_secret"
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

### æŠ€æœ¯æ–‡æ¡£
- [é˜¿é‡Œäº‘æ–‡æ¡£æ™ºèƒ½APIæ–‡æ¡£](https://help.aliyun.com/document_detail/442515.html)
- [Weaviateå®˜æ–¹æ–‡æ¡£](https://weaviate.io/developers/weaviate)
- [LangGraphæ•™ç¨‹](https://langchain-ai.github.io/langgraph/)
- [ç™¾ç‚¼å¤§æ¨¡å‹APIæ–‡æ¡£](https://help.aliyun.com/zh/dashscope/)

### å­¦ä¹ èµ„æº
- RAGæŠ€æœ¯åŸç†ä¸å®è·µ
- å‘é‡æ•°æ®åº“ä½¿ç”¨æŒ‡å—
- æç¤ºè¯å·¥ç¨‹æœ€ä½³å®è·µ
- å¤šè½®å¯¹è¯ç³»ç»Ÿè®¾è®¡

è®°ä½ï¼šé‡åˆ°é—®é¢˜åŠæ—¶æ²Ÿé€šï¼Œä¿æŒä»£ç è´¨é‡ï¼Œæ³¨é‡æ–‡æ¡£è®°å½•ï¼ğŸš€