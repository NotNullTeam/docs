# åç«¯å¼€å‘å›¢é˜Ÿä»»åŠ¡æŒ‡å—

> **å›¢é˜Ÿè§„æ¨¡**: 3äºº  
> **æ ¸å¿ƒèŒè´£**: æ­å»ºæœåŠ¡æ¶æ„ã€å®ç°æ··åˆæ£€ç´¢ç®—æ³•ã€çŸ¥è¯†åº“ç®¡ç†ã€APIå¼€å‘  
> **æŠ€æœ¯æ ˆ**: Python + Flaskã€MySQLã€SQLAlchemyã€RQã€Dockerã€JWTè®¤è¯

## ğŸ“‹ ä»»åŠ¡æ¦‚è§ˆ

### ä¸»è¦ä»»åŠ¡æ¸…å•
- [ ] **ä»»åŠ¡1**: Flaské¡¹ç›®æ­å»ºä¸è®¤è¯ç³»ç»Ÿ (é¢„è®¡2-3å¤©)
- [ ] **ä»»åŠ¡2**: æ•°æ®åº“è®¾è®¡ä¸æ¨¡å‹å®šä¹‰ (é¢„è®¡2-3å¤©)  
- [ ] **ä»»åŠ¡3**: æ ¸å¿ƒä¸šåŠ¡APIå®ç° (é¢„è®¡5-6å¤©)
- [ ] **ä»»åŠ¡4**: çŸ¥è¯†æ–‡æ¡£ç®¡ç†API (é¢„è®¡3-4å¤©)
- [ ] **ä»»åŠ¡5**: å¼‚æ­¥ä»»åŠ¡å¤„ç†ç³»ç»Ÿ (é¢„è®¡3-4å¤©)
- [ ] **ä»»åŠ¡6**: æ•°æ®çœ‹æ¿APIå®ç° (é¢„è®¡2-3å¤©)
- [ ] **ä»»åŠ¡7**: ç³»ç»Ÿé›†æˆä¸æµ‹è¯• (é¢„è®¡3-4å¤©)

---

## ğŸ¯ ä»»åŠ¡1: Flaské¡¹ç›®æ­å»ºä¸è®¤è¯ç³»ç»Ÿ

### 1.1 é¡¹ç›®åˆå§‹åŒ– (ç¬¬1å¤©)

**ç›®æ ‡**: åˆ›å»ºFlaské¡¹ç›®åŸºç¡€ç»“æ„ï¼Œé…ç½®å¼€å‘ç¯å¢ƒã€‚

**å…·ä½“æ­¥éª¤**:

1. **åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æ„**
   ```bash
   mkdir ip-expert-backend
   cd ip-expert-backend
   
   # åˆ›å»ºç›®å½•ç»“æ„
   mkdir -p {app/{api,models,services,utils},config,migrations,tests}
   touch app/__init__.py app/api/__init__.py app/models/__init__.py
   ```

2. **åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ**
   ```bash
   python -m venv venv
   source venv/bin/activate  # Linux/Mac
   # æˆ– venv\Scripts\activate  # Windows
   ```

3. **å®‰è£…ä¾èµ–åŒ…** (`requirements.txt`)
   ```txt
   Flask==2.3.3
   Flask-SQLAlchemy==3.0.5
   Flask-Migrate==4.0.5
   Flask-JWT-Extended==4.5.2
   Flask-CORS==4.0.0
   Flask-WTF==1.1.1
   marshmallow==3.20.1
   redis==4.6.0
   rq==1.15.1
   PyMySQL==1.1.0
   python-dotenv==1.0.0
   requests==2.31.0

   # AIæœåŠ¡ç›¸å…³ä¾èµ–
   langchain>=0.2.0
   langchain_openai>=0.1.0
   dashscope>=1.14.1

   # é˜¿é‡Œäº‘æ–‡æ¡£æ™ºèƒ½æœåŠ¡
   alibabacloud_tea_openapi==0.3.7
   alibabacloud_docmind_api20220711==2.0.1

   # å‘é‡æ•°æ®åº“
   weaviate-client==3.25.3
   ```

4. **åˆ›å»ºåº”ç”¨å·¥å‚** (`app/__init__.py`)
   ```python
   from flask import Flask
   from flask_sqlalchemy import SQLAlchemy
   from flask_migrate import Migrate
   from flask_jwt_extended import JWTManager
   from flask_cors import CORS
   from config import Config
   
   db = SQLAlchemy()
   migrate = Migrate()
   jwt = JWTManager()
   
   def create_app(config_class=Config):
       app = Flask(__name__)
       app.config.from_object(config_class)
       
       # åˆå§‹åŒ–æ‰©å±•
       db.init_app(app)
       migrate.init_app(app, db)
       jwt.init_app(app)
       CORS(app)
       
       # æ³¨å†Œè“å›¾
       from app.api import bp as api_bp
       app.register_blueprint(api_bp, url_prefix='/api/v1')
       
       return app
   ```

**éªŒæ”¶æ ‡å‡†**:
- Flaskåº”ç”¨èƒ½æ­£å¸¸å¯åŠ¨
- é¡¹ç›®ç»“æ„æ¸…æ™°åˆç†
- ä¾èµ–åŒ…å®‰è£…å®Œæˆ

### 1.2 é…ç½®ç®¡ç† (ç¬¬1å¤©)

**ç›®æ ‡**: è®¾ç½®é…ç½®æ–‡ä»¶å’Œç¯å¢ƒå˜é‡ç®¡ç†ã€‚

**å…·ä½“æ­¥éª¤**:

1. **åˆ›å»ºé…ç½®æ–‡ä»¶** (`config.py`)
   ```python
   import os
   from dotenv import load_dotenv
   
   basedir = os.path.abspath(os.path.dirname(__file__))
   load_dotenv(os.path.join(basedir, '.env'))
   
   class Config:
       SECRET_KEY = os.environ.get('SECRET_KEY') or 'dev-secret-key'
       
       # æ•°æ®åº“é…ç½®
       SQLALCHEMY_DATABASE_URI = os.environ.get('DATABASE_URL') or \
           'mysql+pymysql://root:password@localhost/ip_expert'
       SQLALCHEMY_TRACK_MODIFICATIONS = False
       
       # JWTé…ç½®
       JWT_SECRET_KEY = os.environ.get('JWT_SECRET_KEY') or 'jwt-secret'
       JWT_ACCESS_TOKEN_EXPIRES = 3600  # 1å°æ—¶
       
       # Redisé…ç½®
       REDIS_URL = os.environ.get('REDIS_URL') or 'redis://localhost:6379'
       
       # æ–‡ä»¶ä¸Šä¼ é…ç½®
       UPLOAD_FOLDER = os.environ.get('UPLOAD_FOLDER') or 'uploads'
       MAX_CONTENT_LENGTH = 16 * 1024 * 1024  # 16MB
   ```

2. **åˆ›å»ºç¯å¢ƒå˜é‡æ–‡ä»¶** (`.env`)
   ```bash
   SECRET_KEY=your-secret-key-here
   JWT_SECRET_KEY=your-jwt-secret-here
   DATABASE_URL=mysql+pymysql://root:password@localhost/ip_expert
   REDIS_URL=redis://localhost:6379

   # AIæœåŠ¡ç›¸å…³
   DASHSCOPE_API_KEY=your-dashscope-api-key
   OPENAI_API_KEY=your-dashscope-api-key  # ç”¨äºlangchain_openai
   OPENAI_API_BASE=https://dashscope.aliyuncs.com/compatible-mode/v1

   # é˜¿é‡Œäº‘æ–‡æ¡£æ™ºèƒ½æœåŠ¡
   ALIBABA_ACCESS_KEY_ID=your-access-key-id
   ALIBABA_ACCESS_KEY_SECRET=your-access-key-secret
   ```

**éªŒæ”¶æ ‡å‡†**:
- é…ç½®æ–‡ä»¶ç»“æ„åˆç†
- ç¯å¢ƒå˜é‡æ­£ç¡®åŠ è½½
- æ”¯æŒä¸åŒç¯å¢ƒé…ç½®

### 1.3 JWTè®¤è¯ç³»ç»Ÿ (ç¬¬2å¤©)

**ç›®æ ‡**: å®ç°åŸºäºJWTçš„ç”¨æˆ·è®¤è¯ç³»ç»Ÿã€‚

**å…·ä½“æ­¥éª¤**:

1. **åˆ›å»ºç”¨æˆ·æ¨¡å‹** (`app/models/user.py`)
   ```python
   from app import db
   from werkzeug.security import generate_password_hash, check_password_hash
   from datetime import datetime
   
   class User(db.Model):
       id = db.Column(db.Integer, primary_key=True)
       username = db.Column(db.String(80), unique=True, nullable=False)
       email = db.Column(db.String(120), unique=True, nullable=False)
       password_hash = db.Column(db.String(255), nullable=False)
       roles = db.Column(db.String(100), default='user')
       created_at = db.Column(db.DateTime, default=datetime.utcnow)
       is_active = db.Column(db.Boolean, default=True)
       
       def set_password(self, password):
           self.password_hash = generate_password_hash(password)
           
       def check_password(self, password):
           return check_password_hash(self.password_hash, password)
           
       def to_dict(self):
           return {
               'id': self.id,
               'username': self.username,
               'email': self.email,
               'roles': self.roles.split(',') if self.roles else []
           }
   ```

2. **å®ç°è®¤è¯API** (`app/api/auth.py`)
   ```python
   from flask import Blueprint, request, jsonify
   from flask_jwt_extended import create_access_token, jwt_required, get_jwt_identity
   from app.models.user import User
   from app import db
   
   bp = Blueprint('auth', __name__)
   
   @bp.route('/login', methods=['POST'])
   def login():
       data = request.get_json()
       username = data.get('username')
       password = data.get('password')
       
       user = User.query.filter_by(username=username).first()
       
       if user and user.check_password(password) and user.is_active:
           access_token = create_access_token(identity=user.id)
           return jsonify({
               'access_token': access_token,
               'token_type': 'Bearer',
               'user_info': user.to_dict()
           })
       
       return jsonify({'error': 'ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯'}), 401
   
   @bp.route('/me', methods=['GET'])
   @jwt_required()
   def get_current_user():
       user_id = get_jwt_identity()
       user = User.query.get(user_id)
       return jsonify(user.to_dict())
   ```

**éªŒæ”¶æ ‡å‡†**:
- ç”¨æˆ·ç™»å½•åŠŸèƒ½æ­£å¸¸
- JWT tokenç”Ÿæˆå’ŒéªŒè¯æ­£ç¡®
- å—ä¿æŠ¤çš„APIéœ€è¦è®¤è¯

---

## ğŸ¯ ä»»åŠ¡2: æ•°æ®åº“è®¾è®¡ä¸æ¨¡å‹å®šä¹‰

### 2.1 æ•°æ®åº“è®¾è®¡ (ç¬¬1å¤©)

**ç›®æ ‡**: è®¾è®¡å®Œæ•´çš„æ•°æ®åº“è¡¨ç»“æ„ã€‚

**å…·ä½“æ­¥éª¤**:

1. **æ ¸å¿ƒè¡¨è®¾è®¡**
   - users: ç”¨æˆ·è¡¨
   - cases: è¯Šæ–­æ¡ˆä¾‹è¡¨
   - nodes: èŠ‚ç‚¹è¡¨
   - edges: è¾¹è¡¨
   - knowledge_documents: çŸ¥è¯†æ–‡æ¡£è¡¨
   - parsing_jobs: è§£æä»»åŠ¡è¡¨
   - feedback: åé¦ˆè¡¨

2. **åˆ›å»ºæ•°æ®åº“** (MySQL)
   ```sql
   CREATE DATABASE ip_expert CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
   ```

3. **å¯åŠ¨MySQLæœåŠ¡** (Docker)
   ```yaml
   # docker-compose.local.yml ä¸­æ·»åŠ 
   mysql:
     image: mysql:8.0
     ports:
       - "3306:3306"
     environment:
       MYSQL_ROOT_PASSWORD: password
       MYSQL_DATABASE: ip_expert
     volumes:
       - mysql_data:/var/lib/mysql
   ```

**éªŒæ”¶æ ‡å‡†**:
- æ•°æ®åº“è®¾è®¡æ–‡æ¡£å®Œæˆ
- MySQLæœåŠ¡æ­£å¸¸è¿è¡Œ
- æ•°æ®åº“è¿æ¥æµ‹è¯•é€šè¿‡

### 2.2 SQLAlchemyæ¨¡å‹å®šä¹‰ (ç¬¬2å¤©)

**ç›®æ ‡**: å®šä¹‰æ‰€æœ‰æ•°æ®åº“æ¨¡å‹ã€‚

**å…·ä½“æ­¥éª¤**:

1. **æ¡ˆä¾‹ç›¸å…³æ¨¡å‹** (`app/models/case.py`)
   ```python
   from app import db
   from datetime import datetime
   import uuid
   
   class Case(db.Model):
       __tablename__ = 'cases'
       
       id = db.Column(db.String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
       title = db.Column(db.String(200), nullable=False)
       status = db.Column(db.Enum('open', 'solved', 'closed'), default='open')
       user_id = db.Column(db.Integer, db.ForeignKey('user.id'), nullable=False)
       created_at = db.Column(db.DateTime, default=datetime.utcnow)
       updated_at = db.Column(db.DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
       
       # å…³ç³»
       nodes = db.relationship('Node', backref='case', lazy='dynamic', cascade='all, delete-orphan')
       edges = db.relationship('Edge', backref='case', lazy='dynamic', cascade='all, delete-orphan')
   
   class Node(db.Model):
       __tablename__ = 'nodes'
       
       id = db.Column(db.String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
       case_id = db.Column(db.String(36), db.ForeignKey('cases.id'), nullable=False)
       type = db.Column(db.Enum('USER_QUERY', 'AI_ANALYSIS', 'AI_CLARIFICATION', 'USER_RESPONSE', 'SOLUTION'))
       title = db.Column(db.String(200))
       status = db.Column(db.Enum('COMPLETED', 'AWAITING_USER_INPUT', 'PROCESSING'), default='PROCESSING')
       content = db.Column(db.JSON)
       metadata = db.Column(db.JSON)
       created_at = db.Column(db.DateTime, default=datetime.utcnow)
   
   class Edge(db.Model):
       __tablename__ = 'edges'
       
       id = db.Column(db.Integer, primary_key=True)
       case_id = db.Column(db.String(36), db.ForeignKey('cases.id'), nullable=False)
       source = db.Column(db.String(36), nullable=False)
       target = db.Column(db.String(36), nullable=False)
   ```

2. **çŸ¥è¯†æ–‡æ¡£æ¨¡å‹** (`app/models/knowledge.py`)
   ```python
   class KnowledgeDocument(db.Model):
       __tablename__ = 'knowledge_documents'
       
       id = db.Column(db.String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
       filename = db.Column(db.String(255), nullable=False)
       original_filename = db.Column(db.String(255), nullable=False)
       file_path = db.Column(db.String(500), nullable=False)
       file_size = db.Column(db.Integer)
       mime_type = db.Column(db.String(100))
       
       # å…ƒæ•°æ®
       vendor = db.Column(db.String(50))
       tags = db.Column(db.JSON)
       
       # å¤„ç†çŠ¶æ€
       status = db.Column(db.Enum('QUEUED', 'PARSING', 'INDEXED', 'FAILED'), default='QUEUED')
       progress = db.Column(db.Integer, default=0)
       error_message = db.Column(db.Text)
       
       # æ—¶é—´æˆ³
       uploaded_at = db.Column(db.DateTime, default=datetime.utcnow)
       processed_at = db.Column(db.DateTime)
       
       user_id = db.Column(db.Integer, db.ForeignKey('user.id'), nullable=False)
   
   class ParsingJob(db.Model):
       __tablename__ = 'parsing_jobs'
       
       id = db.Column(db.String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
       document_id = db.Column(db.String(36), db.ForeignKey('knowledge_documents.id'), nullable=False)
       status = db.Column(db.Enum('PENDING', 'PROCESSING', 'COMPLETED', 'FAILED'), default='PENDING')
       started_at = db.Column(db.DateTime)
       completed_at = db.Column(db.DateTime)
       error_message = db.Column(db.Text)
       result_data = db.Column(db.JSON)
       
       created_at = db.Column(db.DateTime, default=datetime.utcnow)
   ```

**éªŒæ”¶æ ‡å‡†**:
- æ‰€æœ‰æ¨¡å‹å®šä¹‰å®Œæˆ
- å…³ç³»æ˜ å°„æ­£ç¡®
- æ•°æ®åº“è¿ç§»è„šæœ¬ç”ŸæˆæˆåŠŸ

### 2.3 æ•°æ®åº“è¿ç§» (ç¬¬3å¤©)

**ç›®æ ‡**: åˆ›å»ºå’Œæ‰§è¡Œæ•°æ®åº“è¿ç§»ã€‚

**å…·ä½“æ­¥éª¤**:

1. **åˆå§‹åŒ–è¿ç§»**
   ```bash
   flask db init
   flask db migrate -m "Initial migration"
   flask db upgrade
   ```

2. **åˆ›å»ºåˆå§‹æ•°æ®** (`scripts/init_data.py`)
   ```python
   from app import create_app, db
   from app.models.user import User
   
   def create_admin_user():
       app = create_app()
       with app.app_context():
           admin = User(
               username='admin',
               email='admin@example.com',
               roles='admin,user'
           )
           admin.set_password('admin123')
           db.session.add(admin)
           db.session.commit()
           print("Admin user created successfully")
   
   if __name__ == '__main__':
       create_admin_user()
   ```

**éªŒæ”¶æ ‡å‡†**:
- æ•°æ®åº“è¡¨åˆ›å»ºæˆåŠŸ
- è¿ç§»è„šæœ¬æ­£å¸¸å·¥ä½œ
- åˆå§‹ç®¡ç†å‘˜ç”¨æˆ·åˆ›å»ºæˆåŠŸ

---

## ğŸ¯ ä»»åŠ¡3: æ ¸å¿ƒä¸šåŠ¡APIå®ç°

### 3.1 æ¡ˆä¾‹ç®¡ç†API (ç¬¬1-2å¤©)

**ç›®æ ‡**: å®ç°è¯Šæ–­æ¡ˆä¾‹çš„CRUDæ“ä½œã€‚

**å…·ä½“æ­¥éª¤**:

1. **æ¡ˆä¾‹åˆ—è¡¨API** (`app/api/cases.py`)
   ```python
   from flask import Blueprint, request, jsonify
   from flask_jwt_extended import jwt_required, get_jwt_identity
   from app.models.case import Case, Node, Edge
   from app import db

   bp = Blueprint('cases', __name__)

   @bp.route('/cases', methods=['GET'])
   @jwt_required()
   def get_cases():
       user_id = get_jwt_identity()

       # è·å–æŸ¥è¯¢å‚æ•°
       status = request.args.get('status')
       vendor = request.args.get('vendor')
       category = request.args.get('category')

       query = Case.query.filter_by(user_id=user_id)

       if status:
           query = query.filter_by(status=status)

       cases = query.order_by(Case.updated_at.desc()).all()

       return jsonify([{
           'caseId': case.id,
           'title': case.title,
           'status': case.status,
           'createdAt': case.created_at.isoformat() + 'Z',
           'updatedAt': case.updated_at.isoformat() + 'Z'
       } for case in cases])
   ```

2. **åˆ›å»ºæ¡ˆä¾‹API**
   ```python
   @bp.route('/cases', methods=['POST'])
   @jwt_required()
   def create_case():
       user_id = get_jwt_identity()
       data = request.get_json()

       query = data.get('query')
       attachments = data.get('attachments', [])

       if not query:
           return jsonify({'error': 'é—®é¢˜æè¿°ä¸èƒ½ä¸ºç©º'}), 400

       # åˆ›å»ºæ¡ˆä¾‹
       case = Case(
           title=query[:100] + '...' if len(query) > 100 else query,
           user_id=user_id
       )
       db.session.add(case)
       db.session.flush()  # è·å–case.id

       # åˆ›å»ºç”¨æˆ·é—®é¢˜èŠ‚ç‚¹
       user_node = Node(
           case_id=case.id,
           type='USER_QUERY',
           title='ç”¨æˆ·é—®é¢˜',
           status='COMPLETED',
           content={
               'text': query,
               'attachments': attachments
           }
       )
       db.session.add(user_node)
       db.session.flush()

       # åˆ›å»ºAIåˆ†æèŠ‚ç‚¹
       ai_node = Node(
           case_id=case.id,
           type='AI_ANALYSIS',
           title='AIåˆ†æä¸­...',
           status='PROCESSING'
       )
       db.session.add(ai_node)
       db.session.flush()

       # åˆ›å»ºè¾¹
       edge = Edge(
           case_id=case.id,
           source=user_node.id,
           target=ai_node.id
       )
       db.session.add(edge)

       db.session.commit()

       # è§¦å‘å¼‚æ­¥AIåˆ†æä»»åŠ¡
       from app.services.agent_service import analyze_user_query
       analyze_user_query.delay(case.id, ai_node.id, query)

       return jsonify({
           'caseId': case.id,
           'title': case.title,
           'nodes': [
               {
                   'id': user_node.id,
                   'type': user_node.type,
                   'title': user_node.title,
                   'status': user_node.status,
                   'content': user_node.content
               },
               {
                   'id': ai_node.id,
                   'type': ai_node.type,
                   'title': ai_node.title,
                   'status': ai_node.status
               }
           ],
           'edges': [
               {
                   'source': edge.source,
                   'target': edge.target
               }
           ]
       })
   ```

**éªŒæ”¶æ ‡å‡†**:
- æ¡ˆä¾‹CRUDæ“ä½œæ­£å¸¸
- æ”¯æŒæŸ¥è¯¢å‚æ•°è¿‡æ»¤
- è¿”å›æ•°æ®æ ¼å¼ç¬¦åˆAPIæ–‡æ¡£

### 3.2 å¤šè½®äº¤äº’API (ç¬¬2-3å¤©)

**ç›®æ ‡**: å®ç°Agentå¤šè½®å¯¹è¯äº¤äº’ã€‚

**å…·ä½“æ­¥éª¤**:

1. **äº¤äº’å¤„ç†API**
   ```python
   @bp.route('/cases/<case_id>/interactions', methods=['POST'])
   @jwt_required()
   def handle_interaction(case_id):
       user_id = get_jwt_identity()
       data = request.get_json()

       case = Case.query.filter_by(id=case_id, user_id=user_id).first()
       if not case:
           return jsonify({'error': 'æ¡ˆä¾‹ä¸å­˜åœ¨'}), 404

       parent_node_id = data.get('parentNodeId')
       response_data = data.get('response')
       retrieval_weight = data.get('retrievalWeight', 0.7)
       filter_tags = data.get('filterTags', [])

       # åˆ›å»ºç”¨æˆ·å“åº”èŠ‚ç‚¹
       user_response_node = Node(
           case_id=case_id,
           type='USER_RESPONSE',
           title='ç”¨æˆ·è¡¥å……ä¿¡æ¯',
           status='COMPLETED',
           content=response_data
       )
       db.session.add(user_response_node)
       db.session.flush()

       # åˆ›å»ºAIå¤„ç†èŠ‚ç‚¹
       ai_processing_node = Node(
           case_id=case_id,
           type='AI_ANALYSIS',
           title='AIåˆ†æä¸­...',
           status='PROCESSING'
       )
       db.session.add(ai_processing_node)
       db.session.flush()

       # åˆ›å»ºè¾¹
       edge1 = Edge(case_id=case_id, source=parent_node_id, target=user_response_node.id)
       edge2 = Edge(case_id=case_id, source=user_response_node.id, target=ai_processing_node.id)
       db.session.add_all([edge1, edge2])

       db.session.commit()

       # è§¦å‘å¼‚æ­¥å¤„ç†
       from app.services.agent_service import process_user_response
       process_user_response.delay(
           case_id,
           ai_processing_node.id,
           response_data,
           retrieval_weight,
           filter_tags
       )

       return jsonify({
           'newNodes': [
               {
                   'id': user_response_node.id,
                   'type': user_response_node.type,
                   'title': user_response_node.title,
                   'status': user_response_node.status,
                   'content': user_response_node.content
               },
               {
                   'id': ai_processing_node.id,
                   'type': ai_processing_node.type,
                   'title': ai_processing_node.title,
                   'status': ai_processing_node.status
               }
           ],
           'newEdges': [
               {'source': edge1.source, 'target': edge1.target},
               {'source': edge2.source, 'target': edge2.target}
           ],
           'processingNodeId': ai_processing_node.id
       })
   ```

2. **èŠ‚ç‚¹è¯¦æƒ…API**
   ```python
   @bp.route('/cases/<case_id>/nodes/<node_id>', methods=['GET'])
   @jwt_required()
   def get_node_detail(case_id, node_id):
       user_id = get_jwt_identity()

       case = Case.query.filter_by(id=case_id, user_id=user_id).first()
       if not case:
           return jsonify({'error': 'æ¡ˆä¾‹ä¸å­˜åœ¨'}), 404

       node = Node.query.filter_by(id=node_id, case_id=case_id).first()
       if not node:
           return jsonify({'error': 'èŠ‚ç‚¹ä¸å­˜åœ¨'}), 404

       return jsonify({
           'id': node.id,
           'type': node.type,
           'title': node.title,
           'status': node.status,
           'content': node.content,
           'metadata': node.metadata
       })
   ```

**éªŒæ”¶æ ‡å‡†**:
- å¤šè½®äº¤äº’æµç¨‹æ­£å¸¸
- èŠ‚ç‚¹çŠ¶æ€æ›´æ–°åŠæ—¶
- å¼‚æ­¥ä»»åŠ¡æ­£ç¡®è§¦å‘

### 3.3 åé¦ˆå¤„ç†API (ç¬¬3å¤©)

**ç›®æ ‡**: å®ç°ç”¨æˆ·åé¦ˆæ”¶é›†å’Œå¤„ç†ã€‚

**å…·ä½“æ­¥éª¤**:

1. **åé¦ˆæ¨¡å‹** (`app/models/feedback.py`)
   ```python
   class Feedback(db.Model):
       __tablename__ = 'feedback'

       id = db.Column(db.String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
       case_id = db.Column(db.String(36), db.ForeignKey('cases.id'), nullable=False)
       user_id = db.Column(db.Integer, db.ForeignKey('user.id'), nullable=False)

       outcome = db.Column(db.Enum('solved', 'unsolved'), nullable=False)
       comment = db.Column(db.Text)
       corrected_solution = db.Column(db.JSON)

       # å®¡æ ¸çŠ¶æ€
       review_status = db.Column(db.Enum('pending', 'approved', 'rejected'), default='pending')
       reviewed_by = db.Column(db.Integer, db.ForeignKey('user.id'))
       reviewed_at = db.Column(db.DateTime)

       created_at = db.Column(db.DateTime, default=datetime.utcnow)
   ```

2. **åé¦ˆAPI**
   ```python
   @bp.route('/cases/<case_id>/feedback', methods=['POST'])
   @jwt_required()
   def submit_feedback(case_id):
       user_id = get_jwt_identity()
       data = request.get_json()

       case = Case.query.filter_by(id=case_id, user_id=user_id).first()
       if not case:
           return jsonify({'error': 'æ¡ˆä¾‹ä¸å­˜åœ¨'}), 404

       feedback = Feedback(
           case_id=case_id,
           user_id=user_id,
           outcome=data.get('outcome'),
           comment=data.get('comment'),
           corrected_solution=data.get('corrected_solution')
       )

       db.session.add(feedback)

       # æ›´æ–°æ¡ˆä¾‹çŠ¶æ€
       if data.get('outcome') == 'solved':
           case.status = 'solved'

       db.session.commit()

       return jsonify({
           'status': 'success',
           'message': 'åé¦ˆå·²æ”¶åˆ°'
       })
   ```

**éªŒæ”¶æ ‡å‡†**:
- åé¦ˆæ•°æ®æ­£ç¡®ä¿å­˜
- æ¡ˆä¾‹çŠ¶æ€æ­£ç¡®æ›´æ–°
- æ”¯æŒè§£å†³æ–¹æ¡ˆä¿®æ­£

---

## ğŸ¯ ä»»åŠ¡4: çŸ¥è¯†æ–‡æ¡£ç®¡ç†API

### 4.1 æ–‡ä»¶ä¸Šä¼ API (ç¬¬1å¤©)

**ç›®æ ‡**: å®ç°çŸ¥è¯†æ–‡æ¡£çš„ä¸Šä¼ åŠŸèƒ½ã€‚

**å…·ä½“æ­¥éª¤**:

1. **æ–‡ä»¶ä¸Šä¼ å¤„ç†** (`app/api/knowledge.py`)
   ```python
   import os
   from werkzeug.utils import secure_filename
   from flask import Blueprint, request, jsonify, current_app
   from flask_jwt_extended import jwt_required, get_jwt_identity

   bp = Blueprint('knowledge', __name__)

   ALLOWED_EXTENSIONS = {'pdf', 'doc', 'docx', 'txt', 'md', 'png', 'jpg', 'jpeg'}

   def allowed_file(filename):
       return '.' in filename and \
              filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

   @bp.route('/knowledge/documents', methods=['POST'])
   @jwt_required()
   def upload_document():
       user_id = get_jwt_identity()

       if 'file' not in request.files:
           return jsonify({'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'}), 400

       file = request.files['file']
       if file.filename == '':
           return jsonify({'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'}), 400

       if not allowed_file(file.filename):
           return jsonify({'error': 'ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹'}), 400

       # è·å–è¡¨å•æ•°æ®
       tags = request.form.getlist('tags')
       vendor = request.form.get('vendor')

       # ä¿å­˜æ–‡ä»¶
       filename = secure_filename(file.filename)
       file_id = str(uuid.uuid4())
       file_extension = filename.rsplit('.', 1)[1].lower()
       new_filename = f"{file_id}.{file_extension}"

       upload_folder = current_app.config['UPLOAD_FOLDER']
       os.makedirs(upload_folder, exist_ok=True)
       file_path = os.path.join(upload_folder, new_filename)
       file.save(file_path)

       # ä¿å­˜æ–‡æ¡£è®°å½•
       document = KnowledgeDocument(
           id=file_id,
           filename=new_filename,
           original_filename=filename,
           file_path=file_path,
           file_size=os.path.getsize(file_path),
           mime_type=file.mimetype,
           vendor=vendor,
           tags=tags,
           user_id=user_id
       )

       db.session.add(document)
       db.session.flush()

       # åˆ›å»ºè§£æä»»åŠ¡
       parsing_job = ParsingJob(
           document_id=document.id
       )
       db.session.add(parsing_job)
       db.session.commit()

       # è§¦å‘å¼‚æ­¥è§£æä»»åŠ¡
       from app.services.document_service import parse_document
       parse_document.delay(parsing_job.id)

       return jsonify({
           'docId': document.id,
           'status': 'QUEUED',
           'message': 'æ–‡æ¡£å·²åŠ å…¥å¤„ç†é˜Ÿåˆ—'
       })
   ```

**éªŒæ”¶æ ‡å‡†**:
- æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½æ­£å¸¸
- æ”¯æŒå¤šç§æ–‡ä»¶æ ¼å¼
- æ–‡ä»¶å®‰å…¨æ€§æ£€æŸ¥å®Œå–„

### 4.2 æ–‡æ¡£åˆ—è¡¨å’Œè¯¦æƒ…API (ç¬¬2å¤©)

**ç›®æ ‡**: å®ç°æ–‡æ¡£çš„æŸ¥è¯¢å’Œç®¡ç†åŠŸèƒ½ã€‚

**å…·ä½“æ­¥éª¤**:

1. **æ–‡æ¡£åˆ—è¡¨API**
   ```python
   @bp.route('/knowledge/documents', methods=['GET'])
   @jwt_required()
   def get_documents():
       user_id = get_jwt_identity()

       # è·å–æŸ¥è¯¢å‚æ•°
       status = request.args.get('status')
       vendor = request.args.get('vendor')
       page = int(request.args.get('page', 1))
       page_size = int(request.args.get('pageSize', 10))

       query = KnowledgeDocument.query.filter_by(user_id=user_id)

       if status:
           query = query.filter_by(status=status)
       if vendor:
           query = query.filter_by(vendor=vendor)

       # åˆ†é¡µ
       pagination = query.paginate(
           page=page,
           per_page=page_size,
           error_out=False
       )

       documents = pagination.items

       return jsonify({
           'items': [{
               'docId': doc.id,
               'fileName': doc.original_filename,
               'vendor': doc.vendor,
               'tags': doc.tags,
               'status': doc.status,
               'uploadedAt': doc.uploaded_at.isoformat() + 'Z'
           } for doc in documents],
           'total': pagination.total,
           'page': page,
           'pageSize': page_size
       })
   ```

2. **æ–‡æ¡£è¯¦æƒ…API**
   ```python
   @bp.route('/knowledge/documents/<doc_id>', methods=['GET'])
   @jwt_required()
   def get_document_detail(doc_id):
       user_id = get_jwt_identity()

       document = KnowledgeDocument.query.filter_by(
           id=doc_id,
           user_id=user_id
       ).first()

       if not document:
           return jsonify({'error': 'æ–‡æ¡£ä¸å­˜åœ¨'}), 404

       # è·å–è§£æä»»åŠ¡ä¿¡æ¯
       parsing_job = ParsingJob.query.filter_by(
           document_id=doc_id
       ).order_by(ParsingJob.created_at.desc()).first()

       return jsonify({
           'docId': document.id,
           'fileName': document.original_filename,
           'vendor': document.vendor,
           'tags': document.tags,
           'status': document.status,
           'progress': document.progress,
           'message': parsing_job.error_message if parsing_job else None,
           'createdAt': document.uploaded_at.isoformat() + 'Z',
           'updatedAt': document.processed_at.isoformat() + 'Z' if document.processed_at else None
       })
   ```

**éªŒæ”¶æ ‡å‡†**:
- æ–‡æ¡£åˆ—è¡¨æŸ¥è¯¢æ­£å¸¸
- æ”¯æŒåˆ†é¡µå’Œè¿‡æ»¤
- æ–‡æ¡£è¯¦æƒ…ä¿¡æ¯å®Œæ•´

### 4.3 æ–‡æ¡£åˆ é™¤å’Œé‡è§£æAPI (ç¬¬3å¤©)

**ç›®æ ‡**: å®ç°æ–‡æ¡£çš„åˆ é™¤å’Œé‡æ–°è§£æåŠŸèƒ½ã€‚

**å…·ä½“æ­¥éª¤**:

1. **åˆ é™¤æ–‡æ¡£API**
   ```python
   @bp.route('/knowledge/documents/<doc_id>', methods=['DELETE'])
   @jwt_required()
   def delete_document(doc_id):
       user_id = get_jwt_identity()

       document = KnowledgeDocument.query.filter_by(
           id=doc_id,
           user_id=user_id
       ).first()

       if not document:
           return jsonify({'error': 'æ–‡æ¡£ä¸å­˜åœ¨'}), 404

       # åˆ é™¤ç‰©ç†æ–‡ä»¶
       if os.path.exists(document.file_path):
           os.remove(document.file_path)

       # åˆ é™¤å‘é‡æ•°æ®åº“ä¸­çš„æ•°æ®
       from app.services.vector_service import delete_document_vectors
       delete_document_vectors.delay(doc_id)

       # åˆ é™¤æ•°æ®åº“è®°å½•
       db.session.delete(document)
       db.session.commit()

       return '', 204
   ```

2. **é‡æ–°è§£æAPI**
   ```python
   @bp.route('/knowledge/documents/<doc_id>/reparse', methods=['PUT'])
   @jwt_required()
   def reparse_document(doc_id):
       user_id = get_jwt_identity()

       document = KnowledgeDocument.query.filter_by(
           id=doc_id,
           user_id=user_id
       ).first()

       if not document:
           return jsonify({'error': 'æ–‡æ¡£ä¸å­˜åœ¨'}), 404

       # é‡ç½®çŠ¶æ€
       document.status = 'QUEUED'
       document.progress = 0
       document.error_message = None

       # åˆ›å»ºæ–°çš„è§£æä»»åŠ¡
       parsing_job = ParsingJob(
           document_id=document.id
       )
       db.session.add(parsing_job)
       db.session.commit()

       # è§¦å‘å¼‚æ­¥è§£æ
       from app.services.document_service import parse_document
       parse_document.delay(parsing_job.id)

       return jsonify({
           'docId': document.id,
           'status': 'PARSING',
           'message': 'å·²è§¦å‘é‡æ–°è§£æ'
       })
   ```

**éªŒæ”¶æ ‡å‡†**:
- æ–‡æ¡£åˆ é™¤åŠŸèƒ½æ­£å¸¸
- é‡æ–°è§£æåŠŸèƒ½æ­£å¸¸
- ç›¸å…³æ•°æ®æ¸…ç†å®Œæ•´

---

## ğŸ¯ ä»»åŠ¡5: å¼‚æ­¥ä»»åŠ¡å¤„ç†ç³»ç»Ÿ

### 5.1 RQä»»åŠ¡é˜Ÿåˆ—é…ç½® (ç¬¬1å¤©)

**ç›®æ ‡**: é…ç½®Rediså’ŒRQä»»åŠ¡é˜Ÿåˆ—ç³»ç»Ÿã€‚

**å…·ä½“æ­¥éª¤**:

1. **Redisé…ç½®** (docker-compose.local.yml)
   ```yaml
   redis:
     image: redis:7-alpine
     ports:
       - "6379:6379"
     volumes:
       - redis_data:/data
   ```

2. **RQé…ç½®** (`app/services/__init__.py`)
   ```python
   import redis
   from rq import Queue
   from flask import current_app

   def get_redis_connection():
       return redis.from_url(current_app.config['REDIS_URL'])

   def get_task_queue():
       return Queue('default', connection=get_redis_connection())
   ```

3. **Workerå¯åŠ¨è„šæœ¬** (`worker.py`)
   ```python
   import os
   from rq import Worker
   from app import create_app
   from app.services import get_redis_connection

   if __name__ == '__main__':
       app = create_app()
       with app.app_context():
           redis_conn = get_redis_connection()
           worker = Worker(['default'], connection=redis_conn)
           worker.work()
   ```

**éªŒæ”¶æ ‡å‡†**:
- RedisæœåŠ¡æ­£å¸¸è¿è¡Œ
- RQé˜Ÿåˆ—é…ç½®æ­£ç¡®
- Workerè¿›ç¨‹èƒ½æ­£å¸¸å¯åŠ¨

### 5.2 æ–‡æ¡£è§£ææœåŠ¡ (ç¬¬2å¤©)

**ç›®æ ‡**: å®ç°å¼‚æ­¥æ–‡æ¡£è§£ææœåŠ¡ã€‚

**å…·ä½“æ­¥éª¤**:

1. **æ–‡æ¡£è§£æä»»åŠ¡** (`app/services/document_service.py`)
   ```python
   from rq import get_current_job
   from app import create_app, db
   from app.models.knowledge import KnowledgeDocument, ParsingJob
   from app.services.idp_service import IDPService
   from app.services.vector_service import VectorService

   def parse_document(job_id):
       app = create_app()
       with app.app_context():
           job = ParsingJob.query.get(job_id)
           if not job:
               return

           document = KnowledgeDocument.query.get(job.document_id)
           if not document:
               return

           try:
               # æ›´æ–°çŠ¶æ€
               job.status = 'PROCESSING'
               document.status = 'PARSING'
               db.session.commit()

               # è°ƒç”¨IDPæœåŠ¡è§£ææ–‡æ¡£
               idp_service = IDPService()
               parsed_result = idp_service.parse_document(document.file_path)

               # è¯­ä¹‰åˆ‡åˆ†
               from app.services.semantic_splitter import SemanticSplitter
               splitter = SemanticSplitter()
               chunks = splitter.split_document(parsed_result, document)

               # å‘é‡åŒ–å¹¶å­˜å‚¨
               vector_service = VectorService()
               vector_service.index_chunks(chunks, document.id)

               # æ›´æ–°çŠ¶æ€
               job.status = 'COMPLETED'
               job.result_data = {'chunks_count': len(chunks)}
               document.status = 'INDEXED'
               document.progress = 100
               document.processed_at = datetime.utcnow()

               db.session.commit()

           except Exception as e:
               # é”™è¯¯å¤„ç†
               job.status = 'FAILED'
               job.error_message = str(e)
               document.status = 'FAILED'
               document.error_message = str(e)

               db.session.commit()
               raise
   ```

2. **IDPæœåŠ¡å°è£…** (`app/services/idp_service.py`)
   ```python
   from alibabacloud_docmind_api20220711.client import Client
   from alibabacloud_tea_openapi import models as open_api_models
   import os
   import base64

   class IDPService:
       def __init__(self):
           config = open_api_models.Config(
               access_key_id=os.environ.get('ALIBABA_ACCESS_KEY_ID'),
               access_key_secret=os.environ.get('ALIBABA_ACCESS_KEY_SECRET'),
               endpoint='docmind-api.cn-hangzhou.aliyuncs.com'
           )
           self.client = Client(config)

       def parse_document(self, file_path):
           """
           è°ƒç”¨é˜¿é‡Œäº‘æ–‡æ¡£æ™ºèƒ½APIè§£ææ–‡æ¡£
           """
           try:
               # è¯»å–æ–‡ä»¶å¹¶è½¬æ¢ä¸ºbase64
               with open(file_path, 'rb') as f:
                   file_content = f.read()
                   file_base64 = base64.b64encode(file_content).decode('utf-8')

               # æ„å»ºè¯·æ±‚å‚æ•°
               from alibabacloud_docmind_api20220711 import models as docmind_models

               request = docmind_models.SubmitDocumentExtractJobRequest(
                   file_name=os.path.basename(file_path),
                   file_content=file_base64
               )

               # æäº¤è§£æä»»åŠ¡
               response = self.client.submit_document_extract_job(request)
               job_id = response.body.data.id

               # è½®è¯¢è·å–ç»“æœ
               import time
               while True:
                   query_request = docmind_models.GetDocumentExtractJobRequest(id=job_id)
                   query_response = self.client.get_document_extract_job(query_request)

                   status = query_response.body.data.status
                   if status == 'SUCCESS':
                       return query_response.body.data.result
                   elif status == 'FAILED':
                       raise Exception(f"æ–‡æ¡£è§£æå¤±è´¥: {query_response.body.data.error_message}")

                   time.sleep(2)  # ç­‰å¾…2ç§’åé‡è¯•

           except Exception as e:
               raise Exception(f"IDPæœåŠ¡è°ƒç”¨å¤±è´¥: {str(e)}")
   ```

**éªŒæ”¶æ ‡å‡†**:
- å¼‚æ­¥è§£æä»»åŠ¡æ­£å¸¸æ‰§è¡Œ
- IDPæœåŠ¡é›†æˆæˆåŠŸ
- é”™è¯¯å¤„ç†æœºåˆ¶å®Œå–„

### 5.3 Agentå¤„ç†æœåŠ¡ (ç¬¬3å¤©)

**ç›®æ ‡**: å®ç°Agentå¤šè½®å¯¹è¯çš„å¼‚æ­¥å¤„ç†ã€‚

**å…·ä½“æ­¥éª¤**:

1. **AgentæœåŠ¡** (`app/services/agent_service.py`)
   ```python
   from app.services.retrieval_service import RetrievalService
   from app.services.llm_service import LLMService
   from langchain_openai import ChatOpenAI
   from langchain.schema import HumanMessage, SystemMessage
   import os

   def analyze_user_query(case_id, node_id, query):
       app = create_app()
       with app.app_context():
           try:
               # è·å–èŠ‚ç‚¹
               node = Node.query.get(node_id)
               if not node:
                   return

               # é—®é¢˜åˆ†æ
               llm_service = LLMService()
               analysis_result = llm_service.analyze_query(query)

               # æ£€ç´¢ç›¸å…³çŸ¥è¯†
               retrieval_service = RetrievalService()
               context = retrieval_service.search(query)

               # åˆ¤æ–­æ˜¯å¦éœ€è¦æ›´å¤šä¿¡æ¯
               if analysis_result.get('need_more_info'):
                   # ç”Ÿæˆè¿½é—®
                   clarification = llm_service.generate_clarification(
                       query, analysis_result, context
                   )

                   node.type = 'AI_CLARIFICATION'
                   node.title = 'éœ€è¦æ›´å¤šä¿¡æ¯'
                   node.status = 'AWAITING_USER_INPUT'
                   node.content = {
                       'analysis': analysis_result.get('analysis'),
                       'suggestedQuestions': clarification.get('questions')
                   }
               else:
                   # ç”Ÿæˆè§£å†³æ–¹æ¡ˆ
                   solution = llm_service.generate_solution(
                       query, context, analysis_result
                   )

                   node.type = 'SOLUTION'
                   node.title = 'è§£å†³æ–¹æ¡ˆ'
                   node.status = 'COMPLETED'
                   node.content = {
                       'answer': solution.get('answer'),
                       'sources': solution.get('sources'),
                       'commands': solution.get('commands')
                   }

               db.session.commit()

           except Exception as e:
               # é”™è¯¯å¤„ç†
               node.status = 'COMPLETED'
               node.content = {
                   'error': 'å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œè¯·é‡è¯•'
               }
               db.session.commit()
               raise

   def process_user_response(case_id, node_id, response_data, retrieval_weight, filter_tags):
       # å¤„ç†ç”¨æˆ·è¡¥å……ä¿¡æ¯çš„é€»è¾‘
       pass
   ```

**éªŒæ”¶æ ‡å‡†**:
- Agentå¼‚æ­¥å¤„ç†æ­£å¸¸
- å¤šè½®å¯¹è¯é€»è¾‘æ­£ç¡®
- èŠ‚ç‚¹çŠ¶æ€æ›´æ–°åŠæ—¶

### 5.4 ä»»åŠ¡ç›‘æ§å’Œé‡è¯• (ç¬¬4å¤©)

**ç›®æ ‡**: å®ç°ä»»åŠ¡ç›‘æ§å’Œå¤±è´¥é‡è¯•æœºåˆ¶ã€‚

**å…·ä½“æ­¥éª¤**:

1. **ä»»åŠ¡ç›‘æ§** (`app/services/task_monitor.py`)
   ```python
   from rq import get_current_job
   import logging

   def monitor_task_progress(func):
       def wrapper(*args, **kwargs):
           job = get_current_job()
           if job:
               job.meta['status'] = 'running'
               job.save_meta()

           try:
               result = func(*args, **kwargs)
               if job:
                   job.meta['status'] = 'completed'
                   job.save_meta()
               return result
           except Exception as e:
               if job:
                   job.meta['status'] = 'failed'
                   job.meta['error'] = str(e)
                   job.save_meta()
               logging.error(f"Task failed: {e}")
               raise
       return wrapper
   ```

2. **é‡è¯•æœºåˆ¶**
   ```python
   from rq import Retry

   # åœ¨ä»»åŠ¡è£…é¥°å™¨ä¸­æ·»åŠ é‡è¯•
   @monitor_task_progress
   def parse_document(job_id):
       # ä»»åŠ¡é€»è¾‘
       pass

   # æäº¤ä»»åŠ¡æ—¶æŒ‡å®šé‡è¯•ç­–ç•¥
   queue.enqueue(
       parse_document,
       job_id,
       retry=Retry(max=3, interval=[10, 30, 60])
   )
   ```

**éªŒæ”¶æ ‡å‡†**:
- ä»»åŠ¡ç›‘æ§åŠŸèƒ½æ­£å¸¸
- å¤±è´¥é‡è¯•æœºåˆ¶æœ‰æ•ˆ
- æ—¥å¿—è®°å½•å®Œæ•´

---

## ğŸ¯ ä»»åŠ¡6: æ•°æ®çœ‹æ¿APIå®ç°

### 6.1 ç»Ÿè®¡æ•°æ®èšåˆ (ç¬¬1å¤©)

**ç›®æ ‡**: å®ç°æ•°æ®çœ‹æ¿æ‰€éœ€çš„ç»Ÿè®¡APIã€‚

**å…·ä½“æ­¥éª¤**:

1. **ç»Ÿè®¡API** (`app/api/statistics.py`)
   ```python
   from flask import Blueprint, request, jsonify
   from flask_jwt_extended import jwt_required
   from sqlalchemy import func, and_
   from datetime import datetime, timedelta

   bp = Blueprint('statistics', __name__)

   @bp.route('/statistics', methods=['GET'])
   @jwt_required()
   def get_statistics():
       time_range = request.args.get('timeRange', '30d')

       # è®¡ç®—æ—¶é—´èŒƒå›´
       if time_range == '7d':
           start_date = datetime.utcnow() - timedelta(days=7)
       elif time_range == '90d':
           start_date = datetime.utcnow() - timedelta(days=90)
       else:  # 30d
           start_date = datetime.utcnow() - timedelta(days=30)

       # æ•…éšœåˆ†ç±»ç»Ÿè®¡
       fault_categories = db.session.query(
           Node.metadata['category'].astext.label('category'),
           func.count(Node.id).label('count')
       ).filter(
           and_(
               Node.type == 'USER_QUERY',
               Node.created_at >= start_date
           )
       ).group_by(Node.metadata['category'].astext).all()

       # è§£å†³ç‡è¶‹åŠ¿
       resolution_trend = []
       for i in range(7):
           date = datetime.utcnow() - timedelta(days=i)
           date_str = date.strftime('%Y-%m-%d')

           total_cases = Case.query.filter(
               func.date(Case.created_at) == date.date()
           ).count()

           solved_cases = Case.query.filter(
               and_(
                   func.date(Case.created_at) == date.date(),
                   Case.status == 'solved'
               )
           ).count()

           rate = solved_cases / total_cases if total_cases > 0 else 0
           resolution_trend.append({
               'date': date_str,
               'rate': round(rate, 2)
           })

       # çŸ¥è¯†è¦†ç›–åº¦
       knowledge_coverage = db.session.query(
           KnowledgeDocument.vendor,
           func.count(KnowledgeDocument.id).label('doc_count')
       ).filter(
           KnowledgeDocument.status == 'INDEXED'
       ).group_by(KnowledgeDocument.vendor).all()

       return jsonify({
           'faultCategories': [
               {'name': cat.category or 'Other', 'value': cat.count}
               for cat in fault_categories
           ],
           'resolutionTrend': resolution_trend,
           'knowledgeCoverage': [
               {
                   'topic': 'General',
                   'vendor': cov.vendor or 'Unknown',
                   'coverage': min(cov.doc_count * 10, 100)  # ç®€åŒ–è®¡ç®—
               }
               for cov in knowledge_coverage
           ]
       })
   ```

**éªŒæ”¶æ ‡å‡†**:
- ç»Ÿè®¡æ•°æ®è®¡ç®—æ­£ç¡®
- æ”¯æŒä¸åŒæ—¶é—´èŒƒå›´
- è¿”å›æ ¼å¼ç¬¦åˆå‰ç«¯éœ€æ±‚

### 6.2 æ€§èƒ½ä¼˜åŒ– (ç¬¬2å¤©)

**ç›®æ ‡**: ä¼˜åŒ–ç»Ÿè®¡æŸ¥è¯¢æ€§èƒ½ã€‚

**å…·ä½“æ­¥éª¤**:

1. **æ·»åŠ æ•°æ®åº“ç´¢å¼•**
   ```python
   # åœ¨æ¨¡å‹ä¸­æ·»åŠ ç´¢å¼•
   class Node(db.Model):
       # ... å…¶ä»–å­—æ®µ
       created_at = db.Column(db.DateTime, default=datetime.utcnow, index=True)
       type = db.Column(db.Enum(...), index=True)

   class Case(db.Model):
       # ... å…¶ä»–å­—æ®µ
       created_at = db.Column(db.DateTime, default=datetime.utcnow, index=True)
       status = db.Column(db.Enum(...), index=True)
   ```

2. **ç¼“å­˜æœºåˆ¶**
   ```python
   import redis
   import json
   from functools import wraps

   def cache_result(expire_time=300):
       def decorator(func):
           @wraps(func)
           def wrapper(*args, **kwargs):
               # ç”Ÿæˆç¼“å­˜key
               cache_key = f"stats:{func.__name__}:{hash(str(args) + str(kwargs))}"

               # å°è¯•ä»ç¼“å­˜è·å–
               redis_client = get_redis_connection()
               cached = redis_client.get(cache_key)
               if cached:
                   return json.loads(cached)

               # æ‰§è¡Œå‡½æ•°å¹¶ç¼“å­˜ç»“æœ
               result = func(*args, **kwargs)
               redis_client.setex(cache_key, expire_time, json.dumps(result))
               return result
           return wrapper
       return decorator

   @cache_result(expire_time=600)  # ç¼“å­˜10åˆ†é’Ÿ
   def get_statistics():
       # ç»Ÿè®¡é€»è¾‘
       pass
   ```

**éªŒæ”¶æ ‡å‡†**:
- æŸ¥è¯¢æ€§èƒ½æ˜¾è‘—æå‡
- ç¼“å­˜æœºåˆ¶å·¥ä½œæ­£å¸¸
- æ•°æ®ä¸€è‡´æ€§ä¿è¯

---

## ğŸ¯ ä»»åŠ¡7: ç³»ç»Ÿé›†æˆä¸æµ‹è¯•

### 7.1 APIé›†æˆæµ‹è¯• (ç¬¬1-2å¤©)

**ç›®æ ‡**: è¿›è¡Œå®Œæ•´çš„APIé›†æˆæµ‹è¯•ã€‚

**å…·ä½“æ­¥éª¤**:

1. **æµ‹è¯•ç”¨ä¾‹ç¼–å†™** (`tests/test_api.py`)
   ```python
   import pytest
   from app import create_app, db
   from app.models.user import User

   @pytest.fixture
   def app():
       app = create_app('testing')
       with app.app_context():
           db.create_all()
           yield app
           db.drop_all()

   @pytest.fixture
   def client(app):
       return app.test_client()

   @pytest.fixture
   def auth_headers(client):
       # åˆ›å»ºæµ‹è¯•ç”¨æˆ·å¹¶è·å–token
       user = User(username='test', email='test@example.com')
       user.set_password('password')
       db.session.add(user)
       db.session.commit()

       response = client.post('/api/v1/auth/login', json={
           'username': 'test',
           'password': 'password'
       })
       token = response.get_json()['access_token']
       return {'Authorization': f'Bearer {token}'}

   def test_create_case(client, auth_headers):
       response = client.post('/api/v1/cases',
           headers=auth_headers,
           json={
               'query': 'OSPFé‚»å±…å»ºç«‹å¤±è´¥',
               'attachments': []
           }
       )
       assert response.status_code == 200
       data = response.get_json()
       assert 'caseId' in data
       assert len(data['nodes']) == 2
   ```

2. **è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬**
   ```bash
   #!/bin/bash
   # run_tests.sh

   echo "Running API tests..."
   pytest tests/test_api.py -v

   echo "Running integration tests..."
   pytest tests/test_integration.py -v

   echo "Running performance tests..."
   pytest tests/test_performance.py -v
   ```

**éªŒæ”¶æ ‡å‡†**:
- æ‰€æœ‰APIæµ‹è¯•é€šè¿‡
- é›†æˆæµ‹è¯•è¦†ç›–ä¸»è¦æµç¨‹
- æ€§èƒ½æµ‹è¯•æ»¡è¶³è¦æ±‚

### 7.2 é”™è¯¯å¤„ç†å’Œæ—¥å¿— (ç¬¬2å¤©)

**ç›®æ ‡**: å®Œå–„é”™è¯¯å¤„ç†å’Œæ—¥å¿—ç³»ç»Ÿã€‚

**å…·ä½“æ­¥éª¤**:

1. **å…¨å±€é”™è¯¯å¤„ç†** (`app/errors.py`)
   ```python
   from flask import jsonify
   from app import db

   def register_error_handlers(app):
       @app.errorhandler(400)
       def bad_request(error):
           return jsonify({
               'code': 400,
               'status': 'error',
               'error': {
                   'type': 'INVALID_REQUEST',
                   'message': 'è¯·æ±‚å‚æ•°é”™è¯¯'
               }
           }), 400

       @app.errorhandler(401)
       def unauthorized(error):
           return jsonify({
               'code': 401,
               'status': 'error',
               'error': {
                   'type': 'UNAUTHORIZED',
                   'message': 'æœªæˆæƒè®¿é—®'
               }
           }), 401

       @app.errorhandler(500)
       def internal_error(error):
           db.session.rollback()
           return jsonify({
               'code': 500,
               'status': 'error',
               'error': {
                   'type': 'INTERNAL_ERROR',
                   'message': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'
               }
           }), 500
   ```

2. **æ—¥å¿—é…ç½®** (`app/logging_config.py`)
   ```python
   import logging
   from logging.handlers import RotatingFileHandler
   import os

   def setup_logging(app):
       if not app.debug:
           if not os.path.exists('logs'):
               os.mkdir('logs')

           file_handler = RotatingFileHandler(
               'logs/ip_expert.log',
               maxBytes=10240000,
               backupCount=10
           )
           file_handler.setFormatter(logging.Formatter(
               '%(asctime)s %(levelname)s: %(message)s [in %(pathname)s:%(lineno)d]'
           ))
           file_handler.setLevel(logging.INFO)
           app.logger.addHandler(file_handler)

           app.logger.setLevel(logging.INFO)
           app.logger.info('IP Expert startup')
   ```

**éªŒæ”¶æ ‡å‡†**:
- é”™è¯¯å¤„ç†è¦†ç›–æ‰€æœ‰åœºæ™¯
- æ—¥å¿—è®°å½•è¯¦ç»†å‡†ç¡®
- é”™è¯¯å“åº”æ ¼å¼ç»Ÿä¸€

### 7.3 éƒ¨ç½²å‡†å¤‡ (ç¬¬3å¤©)

**ç›®æ ‡**: å‡†å¤‡ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²é…ç½®ã€‚

**å…·ä½“æ­¥éª¤**:

1. **DockeråŒ–** (`Dockerfile`)
   ```dockerfile
   FROM python:3.9-slim

   WORKDIR /app

   COPY requirements.txt .
   RUN pip install -r requirements.txt

   COPY . .

   EXPOSE 5000

   CMD ["gunicorn", "--bind", "0.0.0.0:5000", "app:create_app()"]
   ```

2. **ç”Ÿäº§é…ç½®** (`docker-compose.prod.yml`)
   ```yaml
   version: '3.8'
   services:
     backend:
       build: .
       ports:
         - "5000:5000"
       environment:
         - FLASK_ENV=production
         - DATABASE_URL=mysql+pymysql://user:pass@mysql/ip_expert
       depends_on:
         - mysql
         - redis

     worker:
       build: .
       command: python worker.py
       depends_on:
         - redis
         - mysql
   ```

**éªŒæ”¶æ ‡å‡†**:
- Dockeré•œåƒæ„å»ºæˆåŠŸ
- ç”Ÿäº§ç¯å¢ƒé…ç½®å®Œæ•´
- æœåŠ¡å¯åŠ¨æ­£å¸¸

---

## ğŸ“Š è¿›åº¦è·Ÿè¸ªä¸è´¨é‡æ§åˆ¶

### æ¯æ—¥ç«™ä¼š
- **æ—¶é—´**: æ¯å¤©ä¸Šåˆ9:00
- **å†…å®¹**: æ±‡æŠ¥æ˜¨æ—¥å®Œæˆæƒ…å†µã€ä»Šæ—¥è®¡åˆ’ã€é‡åˆ°çš„é—®é¢˜
- **å‚ä¸äºº**: åç«¯å›¢é˜Ÿ3äºº + é¡¹ç›®è´Ÿè´£äºº

### ä»£ç å®¡æŸ¥
- **é¢‘ç‡**: æ¯ä¸ªåŠŸèƒ½æ¨¡å—å®Œæˆå
- **æ ‡å‡†**: ä»£ç è§„èŒƒã€å®‰å…¨æ€§ã€æ€§èƒ½ã€æµ‹è¯•è¦†ç›–ç‡
- **å·¥å…·**: Git Pull Request + Code Review

### è´¨é‡æ£€æŸ¥ç‚¹
1. **ç¬¬ä¸€å‘¨æœ«**: åŸºç¡€æ¶æ„å’Œè®¤è¯ç³»ç»ŸéªŒæ”¶
2. **ç¬¬äºŒå‘¨æœ«**: æ ¸å¿ƒAPIåŠŸèƒ½éªŒæ”¶
3. **ç¬¬ä¸‰å‘¨æœ«**: å®Œæ•´ç³»ç»Ÿé›†æˆæµ‹è¯•

### äº¤ä»˜ç‰©æ¸…å•
- [ ] Flaskåç«¯åº”ç”¨ä»£ç 
- [ ] æ•°æ®åº“è®¾è®¡æ–‡æ¡£å’Œè¿ç§»è„šæœ¬
- [ ] APIæ–‡æ¡£å’Œæµ‹è¯•ç”¨ä¾‹
- [ ] å¼‚æ­¥ä»»åŠ¡å¤„ç†ç³»ç»Ÿ
- [ ] Dockeréƒ¨ç½²é…ç½®
- [ ] ç³»ç»Ÿç›‘æ§å’Œæ—¥å¿—é…ç½®

### é£é™©é¢„æ¡ˆ
1. **æ•°æ®åº“æ€§èƒ½é—®é¢˜**: å‡†å¤‡æŸ¥è¯¢ä¼˜åŒ–å’Œç´¢å¼•æ–¹æ¡ˆ
2. **å¼‚æ­¥ä»»åŠ¡å †ç§¯**: å®ç°ä»»åŠ¡ä¼˜å…ˆçº§å’Œé™æµæœºåˆ¶
3. **APIå“åº”è¶…æ—¶**: æ·»åŠ ç¼“å­˜å’Œå¼‚æ­¥å¤„ç†

---

## ğŸ”§ å¼€å‘ç¯å¢ƒé…ç½®

### å¿…éœ€è½¯ä»¶
- Python 3.9+
- MySQL 8.0+
- Redis 7+
- Docker & Docker Compose

### å¼€å‘å·¥å…·
- PyCharm æˆ– VS Code
- Postman (APIæµ‹è¯•)
- MySQL Workbench
- Redis Desktop Manager

### ç¯å¢ƒå˜é‡
```bash
export FLASK_APP=app
export FLASK_ENV=development
export SECRET_KEY=dev-secret-key
export DATABASE_URL=mysql+pymysql://root:password@localhost/ip_expert
export REDIS_URL=redis://localhost:6379

# AIæœåŠ¡ç›¸å…³
export DASHSCOPE_API_KEY=your-dashscope-api-key
export OPENAI_API_KEY=your-dashscope-api-key  # ç”¨äºlangchain_openai
export OPENAI_API_BASE=https://dashscope.aliyuncs.com/compatible-mode/v1

# é˜¿é‡Œäº‘æ–‡æ¡£æ™ºèƒ½æœåŠ¡
export ALIBABA_ACCESS_KEY_ID=your-access-key-id
export ALIBABA_ACCESS_KEY_SECRET=your-access-key-secret
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

### æŠ€æœ¯æ–‡æ¡£
- [Flaskå®˜æ–¹æ–‡æ¡£](https://flask.palletsprojects.com/)
- [SQLAlchemyæ–‡æ¡£](https://docs.sqlalchemy.org/)
- [RQä»»åŠ¡é˜Ÿåˆ—æ–‡æ¡£](https://python-rq.org/)
- [JWTè®¤è¯æœ€ä½³å®è·µ](https://auth0.com/blog/a-look-at-the-latest-draft-for-jwt-bcp/)

### å¼€å‘è§„èŒƒ
- [PEP 8 Pythonä»£ç è§„èŒƒ](https://pep8.org/)
- [RESTful APIè®¾è®¡æŒ‡å—](https://restfulapi.net/)
- [æ•°æ®åº“è®¾è®¡æœ€ä½³å®è·µ](https://www.vertabelo.com/blog/database-design-best-practices/)

è®°ä½ï¼šä¿æŒä»£ç è´¨é‡ï¼Œæ³¨é‡å®‰å…¨æ€§ï¼ŒåŠæ—¶æ²Ÿé€šé—®é¢˜ï¼ğŸš€

